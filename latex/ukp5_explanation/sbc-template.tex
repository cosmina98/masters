\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{fixltx2e}
\usepackage{enumerate}

\usepackage[utf8]{inputenc}  
 
\usepackage{algorithm}
\usepackage{algpseudocode}

\sloppy

\title{The UKP5 Method}

\author{Henrique Becker\inst{1}}

%\address{Instituto de Ciências Exatas e Geociências -- Universidade Passo Fundo (UPF)\\
%  Caixa Postal 611 -- CEP 99001-970 -- Passo Fundo -- RS -- Brasil
\address{Instituto de Informática -- Universidade Federal do Rio Grande do Sul (UFRGS) \\
  Caixa Postal 15064 -- CEP 91501-970 -- Porto Alegre -- RS -- Brasil
  \email{henriquebecker91@gmail.com}
}

\begin{document} 

\maketitle

\section{Introduction}

The objective of this work is to present an algorithm that solves the Unbounded Knapsack Problem (UKP), and to prove its correctness. We name this algorithm UKP5.

\subsection{Definition of the Problem and Chosen Notation}

In this subsection we use the chosen notation to define the UKP. We will use this notation for the rest of the article.

The UKP can be defined as follows: we are given a capacity \(c\), and a list of \(n\) items. Each item \(i \in {1, \ldots, n}\) has a weight value, denoted by \(w_i\), and a profit value, denoted by \(p_i\); we want to know how many of each item (\(x_i\)) we should select to get the biggest possible items profit sum without the items weight sum becoming bigger than the capacity. The problem can be defined using the linear programming notation as follows:

\begin{align}
  maximize: &\sum_{i=1}^n p_i x_i\label{eq:objfun}\\
subject~to: &\sum_{i=1}^n w_i x_i \leq c\label{eq:capcons}\\
            &x_i \in \mathbb{N}_0\label{eq:x_integer}
\end{align}

The capacity \(c\), the quantity \(n\) and the weights of the items \(w_i~(\forall i.~1 \geq i \geq n)\) are all positive integers. The quantities \(x_i~(\forall i.~1 \geq i \geq n)\) are restricted to the non-negative integers, as shown in \eqref{eq:x_integer}. The profit of the items \(p_i~(\forall i.~1 \geq i \geq n)\) are all positive real numbers.

The efficiency of an item \(i\) is the value of \(\frac{p_i}{w_i}\). We will refer to the efficiency of an item as \(e_i\). The UKP5 works faster when the items are ordered by non-decreasing efficiency (i.e. \(i < j\) iff \(\frac{p_i}{w_i} < \frac{p_j}{w_j}\), or simply \(i < j\) iff \(e_i < e_j\) (if two or more items have the same efficiency, we order them by non-decreasing weight). If the items aren't ordered the UKP5 order them first.

We use \(w_{min}\) and \(w_{max}\) to denote the smallest item weight and the biggest item weight, respectively.

\section{The UKP5 algorithm}

The UKP5 algorithm consists on two phases. The first phase find the optimal solution value \(opt\) for the capacity \(c\) by writing values on the arrays \(g\) and \(d\). This phase also outputs the value of first capacity that has the same \(opt\) value as \(c\). What is the same as the weight of the lighter optimal solution for \(c\). Example: if we are solving for capacity 100 and there's an optimal solution of weight 98, and no other optimal solution that weights less, 98 is also returned. We call this value \(y_{opt}\).

The second phase is rather trivial and makes use of the \(y_{opt}\) value and the array \(d\) to create an array \(x\) that represents an optimal solution \(x[i] \equiv x_i\).

\begin{algorithm}
\caption{First Phase -- Computation of $opt$ and $y_{opt}$}\label{alg:ukp6_write_phase}
\begin{algorithmic}[1]
\Procedure{UKP5}{$n, c, w, p, w_{min}, w_{max}$}
  \State \(g \gets\) array of \((c - w_{min}) + w_{max} + 1\) positions each one initialized with \(0\)\label{create_g}
  \State \(d \gets\) array of \((c - w_{min}) + w_{max} + 1\) positions each one initialized with \(n\)\label{create_d}
  
  \For{\(i \gets 1, n\)}\label{begin_trivial_bounds}
    \If{\(g[w_i] < p_i\)}
      \State \(g[w_i] \gets p_i\)
      \State \(d[w_i] \gets i\)
    \EndIf
  \EndFor\label{end_trivial_bounds}

  \State \(opt \gets 0\)\label{init_opt}

  \For{\(y \gets w_{min}, c-w_{min}\)}\label{main_ext_loop_begin}
    \If{\(g[y] \leq opt\)}\label{if_less_than_opt_begin}
    	\State \textbf{continue}
    \EndIf\label{if_less_than_opt_end}
    
    \State \(opt \gets g[y]\)\label{update_opt}
    
    \For{\(i=1,d[y]\)}\label{main_inner_loop_begin}
      \State \(next\_y \gets y + w_i\)\label{calc_values_begin}
      \State \(old\_g\_next\_y \gets g[next\_y]\)
      \State \(new\_g\_next\_y \gets g[y] + p_i\)\label{calc_values_end}
      \If{\(old\_g\_next\_y < new\_g\_next\_y\)}\label{if_new_lower_bound_begin}
        \State \(g[next\_y] \gets new\_g\_next\_y\)
        \State \(d[next\_y] \gets i\)
      \EndIf\label{if_new_lower_bound_end}
    \EndFor\label{main_inner_loop_end}
  \EndFor\label{main_ext_loop_end}

  \For{\(y \gets c-w_{min}+1, c\)}\label{get_y_opt_loop_begin}
    \If{\(g[y] > opt\)}\label{last_loop_inner_if}
      \State \(opt \gets g[y]\)
      \State \(y_{opt} \gets y\)
    \EndIf
  \EndFor\label{get_y_opt_loop_end}
\EndProcedure
\end{algorithmic}
\end{algorithm}

On line~\ref{create_g} we create an array that will store lower bounds for the optimal solution value. We do not guarantee that \(g[y]\) have the optimal solution value for the capacity \(y\), but instead we guarantee that the optimal solution value for the capacity \(y\) can be found on one of the positions between \(g[y-w_{min}+1]\) and \(g[y]\) (both positions included). This can be strange at first as is different by what's done by the classical dynamic programming solutions. This difference is one of the key points of our algorithm and allow us to avoid some unnecessary computation. The explanation that follows will hopefully allow to understand how we give this guarantee.

On line~\ref{create_d} we create an array that will store the index of the most efficient item type that was used to make up a solution. In other words, if \(g[y] \neq 0\) then \(d[y] = i, 1 \geq i \geq n\) where \(i\) is the item of lowest index used to make the solution value stored on \(g[y]\). This assumes that the items are ordered by efficiency, so the item of lowest index used on a solution is the most efficient item used on a solution. If \(g[y] = 0\) then \(d[y] = n\) (because was initialized this way).

On lines~\ref{begin_trivial_bounds}~to~\ref{end_trivial_bounds} we initialize \(g\) and \(d\) with some trivial lower bounds. If there's an item with weight \(w_i\) then there's a solution for the capacity \( y = w_i\) that takes one item \(i\) and nothing more. It can be seen that we update the value of \(d[y]\) with the index of the used item, this way we keep true what we stated on the last paragraph. We will always update \(g[y]\) and \(d[y]\) together. The \textit{if} statement utility is to guarantees that if two items have the same weight only the most efficient one is used.

We initialize the \(opt\) variable (line~\ref{init_opt}). Through the loop of the lines~\ref{main_ext_loop_begin}~to~\ref{main_ext_loop_end}, at the end of an iteration, the \(opt\) variable will store the optimal solution value for the capacity \(y\). The first thing to explain about our outer loop is its range. It begins on \(w_{min}\) because any capacity lower than that will have value zero anyway. It ends on \(c-w_{min}\) because, as in the trivial initialization of the last paragraph, on the iteration \(y\) we update the lower bounds for the capacities between \(y+w_{min}\) to \(y+w_{max}\). If the \(w_{min}\) is, for example, 3 and \(c\) is 100, then 97 will be the last iteration that our algorithm affects the value of \(g[c]\) (or any \(g[y], y < c\)). 

The first \textit{if} at the outer loop is specially important (line~\ref{if_less_than_opt_begin}). It is responsible for only computing the critical points, and in conjunction with the inner loop (line~\ref{main_inner_loop_begin}~to~\ref{main_inner_loop_end}) and the ordering by non-decreasing efficiency, it makes UKP5 use the concepts of dominance and periodicity implicity. The \textit{continue} command makes the control flow to the next iteration, avoiding the execution of the current iteration. This \textit{if} will always evaluate for false at the first iteration because \(opt = 0\) and \(g[w_{min}] > 0\) (all the \(p_i\) values are positive). Initializing \(opt\) with \(0\) instead of the profit value of the item with weight \(w_{min}\) was intentional. For now we will examine the rest of the loop and after this we will return to this \textit{if} statement.

As we are past the \textit{if} then \(g[y]\) can only be bigger than \(opt\). After line~\ref{update_opt}, where \(opt\) is updated, the value of \(opt\) is always guaranteed to be the optimal solution value for capacity \(y\). This is clearly true for the first iteration, as the optimal solution value for capacity \(w_{min}\) is the profit of the lightest item (remember that in our first loop we chose only the most efficient item if the weights were tied). We will explain how it works for the ensuing capacities after we ends this loop analysis. %This guarantee comes from the guarantee that the array \(g\) will always have the solution optimal value for capacity \(y\) in the positions between \(y-w_{min}\) and \(y\).

On line~\ref{main_inner_loop_begin} begins the inner loop, where we update the lower bounds on \(g\). This inner loop iterates from the all-items most efficient item (i.e. item nº \(1\)) to the current capacity optimal solution most efficient used item \(d[y]\). The code inside this inner loop is rather simple. For every item on the above-mentioned range we combine its weight and profit to the current capacity (\(y\)) and optimal solution value \(opt\), respectively, and if this generates a better lower bound for the \(y+w_i\) capacity, we update the \(g[y+w_i]\) value along with the \(d[y+w_i]\) value.

More complex than explaining what the inner loop does is to explain why we can limit ourselves to only iterate until \(d[y]\) intead of \(n\) without affecting the optimal solution value. This behavior has nothing to do with the fact that the item list is ordered by efficiency. In truth, any ordering of the item list will yield the same optimal value. The ordering makes the algorithm run faster, but the algorithm isn't dependent on the item order to reach the optimal solution value. This limit works because every possible solution (not only the optimal ones) can be seen as a list of items, and this list can be constructed by many means (items can be added to it in any order) without affecting the result. Avoiding the addition of items to the solution if, in the item order, they come after an item already used on the solution, we guarantee that the solution will be constructed in the same order that the item list is, and not from many different means, avoiding extra computation. This ideia was already presented on \cite{garfinkel}.

Our first loop (lines~\ref{begin_trivial_bounds}~to~\ref{end_trivial_bounds}) constructs every possible solution with only one item. After that the outer loop (line~\ref{main_ext_loop_begin}) will stop at the positions where those solutions rest, and the inner loop (line~\ref{main_inner_loop_begin}) will contruct all solutions that can be made from that solution adding one more item (an item whose index is equal or lower than the lowest index of an item already used in the solution). When the \textit{if} on line~\ref{if_less_than_opt_begin} skips a position with a value different from zero (but, obviosly, equal or smaller than \(opt\)) it's because there's an item combination that weights less than \(y\) and makes more profit than the one used to make \(g[y]\), so the partial solution used to make the value of \(g[y]\) can be discarded by the algorithm without losing anything.

The skipping process described above is the way, we believe, our \textit{if} implements all the dominances. If for all capacities \(y'\) where \(~y' > y\) the comparison \(d[y] > i\) evaluates for true, then the item \(i\) will not be used anymore. This occurs because were already found partial solutions using more efficient items that can substitute \(i\) for all capacities bigger than \(y'\). For UKP5 apply the concept of dominance, as we just mentioned, the items order must be the non-decreasing efficiency order. Because of this it runs faster when the items are ordered. It works nonetheless if they aren't ordered by efficiency, but the values in \(d\) will decrease slower, slowing our algorithm.

When we are at the end of the outer loop iteration where \(y = y' - w_{min}\) we are sure that \(g[y']\) store the profit sum of the best solution that weights exactly \(y'\). This is the same as if we were solving a variant of the UKP problem where we couldn't leave any free capacity (i.e. if in \eqref{eq:capcons} we had an `\(=\)' instead of an `\(<\)').

Solving this variation of the problem seems counterproductive at first because: 1) if there's no combination of the element weights that sums \(y\), then \(g[y]\) will be zero (that is a valid but very loose lower bound); 2) it's possible to \(g[y]\) be lower than \(g[y']\) where \(y' < y\), because the only way to make the weights sum exactly \(y\) is using less efficient items.

The utility of solving this variation of the problem comes from the following two statements: 1) If the optimal solution of a capacity \(y\) doesn't weights exactly \(y\), then it must weight less than \(y\). This is derived from \eqref{eq:capcons}. If it weights \(y'\), where \(y' < y\), then the value stored on \(g[y']\) will be the knapsack solution optimal value for the capacities \(y'\) to \(y\); 2) If \(y'\) is a capacity with \(g[y'] > g[y'-1]\) (a solution value bigger than the one from the previous capacity) and \(y\) is a capacity where \(y > y'\) and \(g[y] \leq g[y']\), then \(y - y' < w_{min}\). The reason behind this is simple. If \(y - y' \geq w_{min}\) then we would have a solution with profit \(g[y'] + p_i\), where \(w_i = w_{min}\), stored on \(g[y]\), making false our claim that \(g[y] \leq g[y']\). These two facts guarantee that the optimal solution value of a knapsack of size \(c\) will be between \(g[c-w_{min}+1]\) and \(g[c]\) after the outer loop execution execution.

We said before that the periodicity is also implicitly applied on the line~\ref{if_less_than_opt_begin} \(if\) statement. This happens because after some capacity \(y'\), all the values of \(g[y]\) where \(y > y'\) will be \(n\) (and the outer loop will skip it because \(g[y'] = 0\)) or will be \(1\) (and the inner loop will only execute once), greatly reducing the amount of computation done. We can modify UKP5 to explicity check and stop the outer loop when this condition is reached. We avoided doing it here to simplify the explanation and also because in many cases the check overhead waste approximately the same time as letting the program loop for the residual capacity.

After this explanation is easier to see that the first loop (lines~\ref{begin_trivial_bounds}~to~\ref{end_trivial_bounds}) is simply a special case of the inner loop were we construct solutions from the trivial empty solution, instead of the best solution for a capacity \(y\).

The final loop retrieves the \(opt\) and the \(y_{opt}\) values for the optimal solution for capacity \(c\) (lines~\ref{get_y_opt_loop_begin}~to~\ref{get_y_opt_loop_end}). As we already saw, the outer loop ends with \(y = c-w_{min}\). We have the guarantee that \(opt\) isn't the optimal value for \(c\) yet because \(c-w_{min} \not\in \{c-w_{min}+1, \ldots, c\}\). We don't need to initialize \(y_{opt}\) as it's only written, not read, and we are sure that the last loop inner if will evaluate true at least one time.

\begin{algorithm}
\caption{Second Phase -- Construction of \(x\) array}\label{alg:ukp5_second_phase}
\begin{algorithmic}[1]
\Procedure{UKP5\_ASSEMBLE\_X}{$n, w, d, y_{opt}$}
  \State \(x \gets\) array of \(n\) positions each one initialized with \(0\)\label{create_x}
  
  \While{\(y_{opt} \neq 0\)}
    \State \(i \gets d[y_{opt}]\)
    \State Increment \(x[i]\) value by one
    \State \(y_{opt} \gets y_{opt} - w_i\)
  \EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

About the second phase, we can see that, as the found optimal solution is guaranteed to have exactly \(y_{opt}\) weight, we can subtract the solution items weights from \(y_{opt}\) with the guarantee that \(y_{opt}\) will become exactly zero after all solution items are retrieved. As the \(i = d[y_{opt}]\) value is the index of the most efficient item used in the solution, \(d[y_{opt} - w_i]\) will evaluate for the index of the most efficient item used in the rest of the solution, this logic can be applied successive times until all the items that compose the solution are discovered.

\section{An example}

Here we execute the UKP5 first phase algorithm step-by-step with the toy instance presented in \cite{garfinkel}. The instance consists in the following values: \(~c = 25,~w_1 = 6,~w_2 = 4,~w_3 = 3,~w_4 = 1,~p_1 = 11,~p_2 = 7,~p_3 = 5,~p_4 = 1\). The \(w\) and \(p\) order is already the non-decreasing efficiency order. The \(n,~w_{min}\) and \(w_{max}\) values can easily be derived from the instance as \(n = 4,~w_{min} = 1,~w_{max} = 6\). As this article page space is limited, UKP5 first phase never looks back, and only changes values at most \(w_{max}\) positions distant from the current \(y\) value, we will use tables with two times \(w_{max}\) cells.

\begin{table}[h]
\centering
\caption{Memory after line \ref{create_d}}
\label{mem_after_creation}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & 0 &1 &2 &3 &4 &5 &6 &7 &8 &9 &10 &11 &12 &\dots\\
\hline
g: & 0 &0 &0 &0 &0 &0 &0 &0 &0 &0 &0 &0 &0 &\dots\\
d: & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & \dots\\
\end{tabular}
\end{table}

Trivial, the memory was simply initialized.

\begin{table}[h]
\centering
\caption{Memory after line \ref{end_trivial_bounds}}
\label{mem_after_trivial_bounds}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & 0 &\textbf{1} &2 &\textbf{3} &\textbf{4} &5 &\textbf{6} &7 &8 &9 &10 &11 &12 &\dots\\
\hline
g: & 0 & \textbf{1} &0 &\textbf{5} &\textbf{7} &0 &\textbf{11} &0 &0 &0 &0 &0 &0 &\dots\\
d: & 4 & \textbf{4} & 4 & \textbf{3} & \textbf{2} & 4 & \textbf{1} & 4 & 4 & 4 & 4 & 4 & 4 & \dots\\
\end{tabular}
\end{table}

Also rather simple, every \(y = w_i\) for some \(i\) now have \(p_i\) (\(g\) array) or \(i\) (\(d\) array).

\begin{table}[H]
\centering
\caption{Memory at end of the outer loop (line \ref{main_ext_loop_end}) where (y = 1)}
\label{mem_y_1}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & 0 & \textbf{1} &2 &3 &4 &5 &6 &7 &8 &9 &10 &11 &12 &\dots\\
\hline
g: & 0 & \textbf{1} &\textbf{2} &5 &\textbf{7} &\textbf{8} &11 &\textbf{12} &0 &0 &0 &0 &0 &\dots\\
d: & 4 & \textbf{4} & \textbf{4} & 3 & \textbf{2} & \textbf{2} & 1 & \textbf{1} & 4 & 4 & 4 & 4 & 4 & \dots\\
\end{tabular}
\end{table}

The first iteration begins with \(y = w_{min} = 1\). Now we will use the following notation: the first all bold column is the one who the capacity \(y\) is equal to the \(y\) variable in the current outer loop; after this first column, the bold \(g\) and \(d\) values are the ones that were updated by the inner loop (a better bound was found in this iteration). Note that the \(d\) value can be updated for the same value it already had (especially when we use the least efficient item where the \(d[y]\) was \(n\)), but we will display it on bold font nonetheless. This iteration the item \(i = 4,~w_i = p_i = 1\) is combined with all items to make bounds for the capacities \(2, 4, 5\) and \(7\).

\begin{table}[h]
\centering
\caption{Memory at end of the outer loop (line \ref{main_ext_loop_end}) where (y = 2)}
\label{mem_y_2}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & 0 &1 &\textbf{2} &3 &4 &5 &6 &7 &8 &9 &10 &11 &12 &\dots\\
\hline
g: & 0 &1 &\textbf{2} &5 &7 &8 &11 &12 &\textbf{13} &0 &0 &0 &0 &\dots\\
d: & 4 & 4 &\textbf{4} & 3 & 2 & 2 & 1 & 1 & \textbf{1} & 4 & 4 & 4 & 4 & \dots\\
\end{tabular}
\end{table}

Here we see that combining two of the least efficient item with all items only improves the solution value for the capacity \(y = 8\) (whose previous solution was the trivial empty solution).

\pagebreak
\begin{table}[H]
\centering
\caption{Memory at end of the outer loop (line \ref{main_ext_loop_end}) where (y = 3)}
\label{mem_y_3}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & 0 &1 &2 & \textbf{3} &4 &5 &6 &7 &8 &9 &10 &11 &12 &\dots\\
\hline
g: & 0 &1 &2 & \textbf{5} &7 &8 &11 &12 &13 &\textbf{16} &0 &0 &0 &\dots\\
d: & 4 & 4 & 4 & \textbf{3} & 2 & 2 & 1 & 1 & 1 & \textbf{1} & 4 & 4 & 4 & \dots\\
\end{tabular}
\end{table}

Combining the item \(3\) with items \(1, 2\) and \(3\) also only yield one improvement (and also from the trivial empty solution). We don't combine with all items in this iteration because \(d[y] = 3\).

\begin{table}[H]
\centering
\caption{Memory at end of the outer loop (line \ref{main_ext_loop_end}) where (y = 4)}
\label{mem_y_4}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & 0 &1 &2 &3 &\textbf{4} &5 &6 &7 &\textbf{8} &9 &\textbf{10} &11 &12 &\dots\\
\hline
g: & 0 &1 &2 &5 &\textbf{7} &8 &11 &12 &\textbf{14} &16 &\textbf{18} &0 &0 &\dots\\
d: & 4 & 4 & 4 & 3 & \textbf{2} & 2 & 1 & 1 & \textbf{2} & 1 & \textbf{1} & 4 & 4 & \dots\\
\end{tabular}
\end{table}

Combining the item \(2\) with the first an the second items yield an improvement on an already existing non-trivial solution bound (\(y = 8\)), and shows that an \(d[y]\) value can increase value again after decreasing (\(d[8]\) changed from \(n\) to \(1\), and now increased to \(2\)). We will not comment anymore on the improvements made over the trivial empty solution, since it's already clear that they will happen every iteration, when combining the current solution with the item of the largest weight, who's the first item, and will always be avaliable for combination.

\begin{table}[h]
\centering
\caption{Memory at end of the outer loop (line \ref{main_ext_loop_end}) where (y = 5)}
\label{mem_y_5}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & 0 &1 &2 &3 &4 &\textbf{5} &6  &7  &8  &9  &10 &\textbf{11} &12 &\dots\\
\hline
g: & 0 &1 &2 &5 &7 &\textbf{8} &11 &12 &14 &16 &18 &\textbf{19} &0 &\dots\\
d: & 4 & 4 & 4 & 3 & 2 & \textbf{2}& 1 & 1 & 2 & 1 & 1 & \textbf{1} & 4 & \dots\\
\end{tabular}
\end{table}

No comments.

\begin{table}[h]
\centering
\caption{Memory at end of the outer loop (line \ref{main_ext_loop_end}) where (y = 6)}
\label{mem_y_6}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & \textbf{6} &7   &8  &9  &10 &11 &\textbf{12} &13 &14 &15 &16 &17 &18 &\dots\\
\hline
g: & \textbf{11} &12 &14 &16 &18 &19 &\textbf{22} &0 &0 &0 &0 &0 &0 &\dots\\
d: & \textbf{1} & 1  & 2 & 1 & 1 & 1 & \textbf{1} & 4& 4 & 4 & 4 & 4 & 4 & \dots\\
\end{tabular}
\end{table}

We shift the memory \(w_{max}\) positions to continue example (now the first \(y\) column is \(6\)). 

\begin{table}[H]
\centering
\caption{Memory at end of the outer loop (line \ref{main_ext_loop_end}) where (y = 7)}
\label{mem_y_7}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & 6 &\textbf{7} &8 &9 &10 &11 &12 &\textbf{13} &14 &15 &16 &17 &18 &\dots\\
\hline
g: & 11 &\textbf{12} &14 &16 &18 &19 &22 &\textbf{23} &0 &0 &0 &0 &0 &\dots\\
d: & 1 & \textbf{1} & 2 & 1 & 1 & 1 & 1 & \textbf{1} & 4 & 4 & 4 & 4 & 4 & \dots\\
\end{tabular}
\end{table}

No comment.

\begin{table}[H]
\centering
\caption{Memory at end of the outer loop (line \ref{main_ext_loop_end}) where (y = 8)}
\label{mem_y_8}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & 6 &7 &\textbf{8} &9 &10 &11 &12 &13 &\textbf{14} & 15 &16 &17 &18 &\dots\\
\hline
g: & 11 &12 &\textbf{14} &16 &18 &19 &22 &23 &\textbf{25} &0 &0 &0 &0 &\dots\\
d: & 1 & 1 & \textbf{2} & 1 & 1 & 1 & 1 & 1 & \textbf{1} & 4 & 4 & 4 & 4 & \dots\\
\end{tabular}
\end{table}

No comment.

\begin{table}[H]
\centering
\caption{Memory at end of the outer loop (line \ref{main_ext_loop_end}) where (y = 9)}
\label{mem_y_9}
\begin{tabular}{l|rrrrrrrrrrrrrr}
y: & 6 &7 &8 &\textbf{9} &10 &11 &12 &13 &14 &\textbf{15} &16 &17 &18 &\dots\\
\hline
g: & 11 &12 &14 &\textbf{16} &18 &19 &22 &23 &25 &\textbf{27} &0 &0 &0 &\dots\\
d: & 1 & 1 & 2 & \textbf{1} & 1 & 1 & 1 & 1 & 1 & \textbf{1} & 4 & 4 & 4 & \dots\\
\end{tabular}
\end{table}

Here something important happens. At the end of this outer loop, all the next \(d[y]\) values or are \(1\), or are \(n\) with \(g[y] = 0\). We already discussed this situation before at last section, when we said that the UKP5 implements periodicity implicity. As the inner loop will now only make the first iteration, our processing is reduced to \(\frac{1}{n} = \frac{1}{4}\) of the version without \(d\). If we were storing the position of the last \(d[y'] > 1\) and saw that \(y' < y\) we could interrupt the loop now and calculate the filling for the extra capacity by a simple formula.

\end{document} 

\bibliographystyle{sbc.bst}
\bibliography{sbc-template.bib}

\end{document}

