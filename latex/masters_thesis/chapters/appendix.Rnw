\chapter{Tables}

<<setup,echo=F>>=
library(xtable)
library(statsr)
library(dplyr)

get_n <- function(fname) {
  gsub(".*[^i]n([1-9][0-9]+).*", "\\1", fname)
}

get_wmin <- function(row) {
  if (row[8] == 'hi') {
    row[9]
  } else {
    gsub(".*wmin([1-9][0-9]+).*", "\\1", row[2])
  }
}

get_dist <- function(fname) {
  gsub("([^_]+).*", "\\1", fname)
}

get_alpha <- function(fname) {
  gsub(".*a([5-][5]?).*", "\\1", fname)
}
@

<<pya_table,echo=false>>=
# THIS IS THE SOURCE FOR THE VALUES IN THE TABLE BELOW,
# THEY WERE COPIED BY HAND BY THE AUTHOR USING RSTUDIO
fast <- read.csv("../data/pya_ukp5.csv", sep = ";")
fast$X <- NULL

t <- fast %>% mutate(dist = get_dist(filename)) %>% mutate(n = get_n(filename))
t$wmin <- apply(t, 1, get_wmin)

ss2 <- filter(t, dist == "ss2") %>% select(algorithm, internal_time) %>%
      group_by(algorithm) %>% summarise(avg = mean(internal_time), sd = sd(internal_time), max = max(internal_time))

get_alpha <- function(fname) {
  gsub(".*a([5-][5]?).*", "\\1", fname)
}

sc <- filter(t, dist == "sc") %>% mutate(a = get_alpha(filename)) %>%
      mutate(n = as.numeric(n), wmin = as.numeric(wmin)) %>%
      select(algorithm, a, n, wmin, internal_time) %>% group_by(algorithm, a, n, wmin) %>%
      summarise(avg = round(mean(internal_time), digits = 2), sd = round(sd(internal_time), digits = 2), max = round(max(internal_time), digits = 2))

table_for_dist <- function(dist_in) {
  filter(t, dist == dist_in) %>% mutate(n = as.numeric(n), wmin = as.numeric(wmin)) %>%
    select(algorithm, n, wmin, internal_time) %>% group_by(algorithm, n, wmin) %>%
    summarise(avg = round(mean(internal_time), digits = 2), sd = round(sd(internal_time), digits = 2), max = round(max(internal_time), digits = 2))
}

nsds2 <- table_for_dist("nsds2")
hi <- table_for_dist("hi")
saw <- table_for_dist("saw")
@

\begin{table}
\caption{Results for the PYAsUKP 4540 Instances (see Section \ref{sec:pya_exp}). Columns \textbf{n} and \(w_{min}\) values must be multiplied by \(10^3\) to obtain their true value. Let \(T\) be the set of times reported by UKP5, MGREENDP1 or EDUK2 for the instance dataset described by a row. The meaning of the columns \textbf{avg}, \textbf{sd} and \textbf{max}, is, respectively, the arithmetic mean of \(T\), the standard deviation of \(T\), the maximum value of \(T\). The time unit of the table values is seconds.}
\vspace{0.1cm}
\label{tab:times_pya}
\def\arraystretch{1.1}
\setlength\tabcolsep{4px}

\begin{tabular}{@{\extracolsep{4pt}}rrrrrrrrrrrr@{}}

\hline
\multicolumn{3}{l}{Instance desc.} & \multicolumn{3}{l}{UKP5} & \multicolumn{3}{l}{MGREENDP} & \multicolumn{3}{l}{PYAsUKP}\\
\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}

\multicolumn{3}{l}{400 inst. per line} & \multicolumn{9}{l}{Subset-sum. Random \emph{c} between \([5\times10^6; 10^7]\)}\\
\cline{1-3}\cline{4-12}

& \textbf{n} & \(w_{min}\)  & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max}\\
\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}

\multicolumn{3}{c}{See section~\ref{sec:subsetsum}} & 0.05 & 0.12 & 0.74 & -- & -- & -- & 2.52 & 21.75 & 302.51 \\
\hline

\multicolumn{3}{l}{20 inst. per line} & \multicolumn{9}{l}{Strong correlation. Random \emph{c} between \([20\overline{n}; 100\overline{n}]\)}\\
\cline{1-3}\cline{4-12}
\textbf{\(\alpha\)} & \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max}\\

\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}
 5 & 5  & 10 & 0.03 & 0.00 & 0.03 &  0.24 & 0.03 &  0.29 & 1.57 & 1.78 & 3.62\\
   &    & 15 & 0.04 & 0.00 & 0.05 &  0.43 & 0.06 &  0.53 & 3.85 & 1.53 & 5.13\\
   &    & 50 & 0.13 & 0.00 & 0.16 &  1.01 & 0.52 &  1.70 & 12.12 & 8.17 & 28.84\\
 5 & 10 & 10 & 0.06 & 0.00 & 0.06 &  0.50 & 0.04 &  0.54 & 0.00 & 0.00 & 0.01\\
   &    & 50 & 0.29 & 0.00 & 0.30 &  5.93 & 0.82 &  6.79 & 22.43 & 17.85 & 45.19\\
   &    & 110& 0.66 & 0.00 & 0.66 & 16.05 & 3.36 & 19.68 & 76.53 & 62.54 & 175.61\\
-5 & 5  & 10 & 0.04 & 0.00 & 0.05 & 0.04 & 0.00 & 0.04 & 4.02 & 2.72 & 7.12\\
   &    & 15 & 0.05 & 0.00 & 0.05 & 0.05 & 0.00 & 0.05 & 6.76 & 4.22 & 12.24\\
   &    & 50 & 0.14 & 0.00 & 0.15 & 0.11 & 0.02 & 0.12 & 24.76 & 19.41 & 66.23\\
-5 & 10 & 10 & 0.10 & 0.00 & 0.10 & 0.11 & 0.01 & 0.13 & 6.74 & 6.28 & 15.38\\
   &    & 50 & 0.32 & 0.00 & 0.32 & 0.28 & 0.01 & 0.29 & 48.70 & 42.53 & 111.61\\
   &    & 110& 0.65 & 0.00 & 0.66 & 0.52 & 0.01 & 0.53 & 144.87 & 143.53 & 416.41\\
\hline

\multicolumn{3}{l}{200 inst. per line} & \multicolumn{9}{l}{Postponed periodicity. Random \emph{c} between \([w_{max}; 2\times10^6]\)}\\
\cline{1-3}\cline{4-12}
& \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max}\\
\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}
& 20 & 20 & 0.79 & 0.10 & 0.97 & 0.74 & 0.11 & 0.96 & 8.65 & 7.74 & 28.63\\
& 50 & 20 & 5.70 & 0.37 & 6.54 & 5.12 & 0.65 & 6.13 & 78.34 & 82.46 & 356.67\\
& 20 & 50 & 0.89 & 0.12 & 1.19 & 0.75 & 0.14 & 1.09 & 11.57 & 8.20 & 39.20\\
& 50 & 50 & 4.72 & 0.69 & 6.27 & 3.97 & 0.75 & 5.30 & 113.21 & 87.16 & 267.10\\
\hline

\multicolumn{3}{l}{500 inst. per line} & \multicolumn{9}{l}{No collective dominance. Random \emph{c} between \([w_{max}; 1000\overline{n}]\)}\\
\cline{1-3}\cline{4-12}
& \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max}\\
\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}
&  5 & n & 0.07 & 0.03 & 0.14 & 0.04 & 0.01 & 0.07 & 0.59 & 0.44 & 2.03\\
& 10 & n & 0.65 & 0.31 & 1.30 & 0.33 & 0.10 & 0.60 & 2.34 & 1.86 & 8.44\\
& 20 & n & 1.04 & 0.32 & 1.91 & 0.72 & 0.12 & 1.31 & 8.62 & 7.64 & 31.22\\
& 50 & n & 3.64 & 0.36 & 4.74 & 3.56 & 0.20 & 4.46 & 73.49 & 72.26 & 279.01\\
\hline

\multicolumn{3}{l}{\emph{qtd} inst. per line} & \multicolumn{9}{l}{SAW. Random \emph{c} between \([w_{max}; 10\overline{n}]\)}\\
\cline{1-3}\cline{4-12}
\textbf{qtd} & \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max}\\
\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}
~200 &  10 & 10 & 0.08 & 0.00 & 0.09 & 0.14 & 0.02 & 0.21 & 1.32 & 0.85 & 3.01\\
~500 &  50 &  5 & 0.50 & 0.01 & 0.53 & 2.09 & 1.00 & 3.75 & 3.36 & 2.86 & 11.16\\
~200 &  50 & 10 & 0.72 & 0.01 & 0.74 & 2.15 & 0.85 & 3.65 & 6.99 & 5.81 & 23.04\\
~200 & 100 & 10 & 7.34 & 0.32 & 8.09 & 33.93 & 6.94 & 43.40 & 40.43 & 35.13 & 118.28\\
\hline

\end{tabular}
\end{table}

% MTUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUU

<<pya_table,echo=false>>=
# THIS IS THE SOURCE FOR THE VALUES IN THE TABLE BELOW,
# THEY WERE COPIED BY HAND BY THE AUTHOR USING RSTUDIO
slow <- read.csv("../data/mtu_impl_desktop_uc1.csv", sep = ";")
slow$X <- NULL

t <- slow %>% mutate(dist = get_dist(filename)) %>% mutate(n = get_n(filename))
t$wmin <- apply(t, 1, get_wmin)

ss2 <- filter(t, dist == "ss2") %>% select(algorithm, internal_time) %>%
      group_by(algorithm) %>% summarise(avg = round(mean(internal_time, na.rm = TRUE), digits = 2), ter = sum(!is.na(internal_time)))

sc <- filter(t, dist == "sc") %>% mutate(a = get_alpha(filename)) %>%
      mutate(n = as.numeric(n), wmin = as.numeric(wmin)) %>%
      select(algorithm, a, n, wmin, internal_time) %>% group_by(algorithm, a, n, wmin) %>%
      summarise(avg = round(mean(internal_time, na.rm = TRUE), digits = 2), ter = sum(!is.na(internal_time)))

table_for_dist <- function(dist_in) {
  filter(t, dist == dist_in) %>% mutate(n = as.numeric(n), wmin = as.numeric(wmin)) %>%
    select(algorithm, n, wmin, internal_time) %>% group_by(algorithm, n, wmin) %>%
    summarise(avg = round(mean(internal_time, na.rm = TRUE), digits = 2), ter = sum(!is.na(internal_time)))
}

nsds2 <- table_for_dist("nsds2")
hi <- table_for_dist("hi")
saw <- table_for_dist("saw")

@
\begin{table}
\caption{Results for the MTU implementatios over the reduced PYAsUKP's dataset (see Section \ref{sec:mtu_exp}). Columns \textbf{n} and \(w_{min}\) values must be multiplied by \(10^3\) to obtain their true value. Let \(T\) be the set of times reported by CPP-MTU1, CPP-MTU2, F77-MTU1 and F77-MTU2, for the instance dataset described by a row (in this case, we don't count runs that ended in timeout). The meaning of the columns \textbf{avg} and \textbf{ter}, is, respectively, the arithmetic mean of \(T\) and the cardinality of \(T\) (i.e. the number of runs that didn't end in timeout). The time unit of the table values is seconds.}
\vspace{0.1cm}
\label{tab:times_mtu}
\def\arraystretch{1.1}
\setlength\tabcolsep{6px}

\begin{tabular}{@{\extracolsep{4pt}}rrrrrrrrrrr@{}}

\hline
\multicolumn{3}{l}{Instance desc.} & \multicolumn{2}{c}{CPP-MTU1} & \multicolumn{2}{c}{CPP-MTU2} & \multicolumn{2}{c}{F77-MTU1} & \multicolumn{2}{c}{F77-MTU2}\\
\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}

\multicolumn{3}{l}{40 inst. per line} & \multicolumn{8}{l}{Subset-sum. Random \emph{c} between \([5\times10^6; 10^7]\)}\\
\cline{1-3}\cline{4-11}

& \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{ter}  & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter}\\
\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}

\multicolumn{3}{c}{See section~\ref{sec:subsetsum}} & 0.04 & 40 & 0.04 & 40 & 0.00 & 40 & 154.97 & 8\\
\hline

\multicolumn{3}{l}{2 inst. per line} & \multicolumn{8}{l}{Strong correlation. Random \emph{c} between \([20\overline{n}; 100\overline{n}]\)}\\
\cline{1-3}\cline{4-11}
\textbf{\(\alpha\)} & \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{ter}  & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter}\\

\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}
 5 & 5  & 10 & 0.00 & 1 &   -- & 0 & 0.00 & 1 &   -- & 0\\
   &    & 15 &   -- & 0 &   -- & 0 &   -- & 0 &   -- & 0\\
   &    & 50 &   -- & 0 &   -- & 0 &   -- & 0 &   -- & 0\\
 5 & 10 & 10 & 0.00 & 1 &   -- & 0 & 0.00 & 1 &   -- & 0\\
   &    & 50 & 0.04 & 1 &   -- & 0 & 0.03 & 1 &   -- & 0\\
   &    & 110& 0.01 & 1 &   -- & 0 & 0.00 & 1 &   -- & 0\\
-5 & 5  & 10 &   -- & 0 &   -- & 0 &   -- & 0 &   -- & 0\\
   &    & 15 &   -- & 0 &   -- & 0 &   -- & 0 &   -- & 0\\
   &    & 50 &   -- & 0 &   -- & 0 &   -- & 0 &   -- & 0\\
-5 & 10 & 10 & 0.00 & 1 &   -- & 0 & 0.00 & 1 &   -- & 0\\
   &    & 50 & 0.00 & 1 & 0.79 & 1 & 0.00 & 1 & 0.83 & 1\\
   &    & 110& 0.00 & 1 &   -- & 0 & 0.00 & 1 &   -- & 0\\
\hline

\multicolumn{3}{l}{20 inst. per line} & \multicolumn{8}{l}{Postponed periodicity. Random \emph{c} between \([w_{max}; 2\times10^6]\)}\\
\cline{1-3}\cline{4-11}
& \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{ter}  & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter}\\
\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}
& 20 & 20 &  67.17 & 19 & 67.17 & 19 &  18.05 & 17 &  15.12 & 17\\
& 50 & 20 & 101.93 & 18 &  2.15 & 20 & 134.09 & 17 & 143.47 & 17\\
& 20 & 50 &   3.15 & 20 &  1.74 & 20 &   6.33 & 20 &   7.83 & 20\\
& 50 & 50 &   2.22 & 20 & 21.13 & 20 &   4.45 & 20 &  13.81 & 20\\
\hline

\multicolumn{3}{l}{50 inst. per line} & \multicolumn{8}{l}{No collective dominance. Random \emph{c} between \([w_{max}; 1000\overline{n}]\)}\\
\cline{1-3}\cline{4-11}
& \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter}\\
\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}
&  5 & n &  16.54 & 9 & 37.01 & 9 & 19.85 & 9 & 37.29 & 9\\
& 10 & n & 147.08 & 6 &  5.84 & 5 & 34.41 & 5 & 10.09 & 5\\
& 20 & n &  17.95 & 3 & 19.23 & 3 & 27.45 & 3 & 27.78 & 3\\
& 50 & n &  13.36 & 2 &  1.40 & 2 & 26.73 & 2 &  2.64 & 2\\
\hline

\multicolumn{3}{l}{\emph{qtd} inst. per line} & \multicolumn{8}{l}{SAW. Random \emph{c} between \([w_{max}; 10\overline{n}]\)}\\
\cline{1-3}\cline{4-11}
\textbf{qtd} & \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{ter}  & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter} & \textbf{avg} & \textbf{ter}\\
\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}
~20 &  10 & 10 &  1.33 & 20 & 12.92 & 20 &  2.54 & 20 &  2.87 & 20\\
~50 &  50 &  5 & 43.08 & 46 & 43.97 & 19 & 59.14 & 38 & 38.63 & 16\\
~20 &  50 & 10 & 55.14 & 45 & 87.68 & 19 & 47.05 & 41 & 85.97 & 19\\
~20 & 100 & 10 & 10.10 & 16 & 38.41 & 17 & 20.23 & 16 & 44.41 & 16\\
\hline
\end{tabular}
\end{table}

<<breq_table,echo=false,results=tex>>=
breq <- read.csv("../data/128_16_std_breqd_all.csv", sep = ";")
breq$X <- NULL

get_n <- function(fname) {
  gsub(".*-n([1-9][0-9]+).*", "\\1", fname)
}

format_n <- function(x) {
  str <- toString(round(x, digits = 2))
  gsub("(NA|NaN)", "--", str)
}

t <- breq %>% mutate(n = as.integer(get_n(filename))) %>%
  select(algorithm, n, internal_time) %>% group_by(algorithm, n) %>%
  summarise(avg = format_n(mean(internal_time, na.rm = TRUE)),
            sd = format_n(sd(internal_time, na.rm = TRUE)),
            min = format_n(min(internal_time, na.rm = TRUE)),
            max = format_n(max(internal_time, na.rm = TRUE)),
            ter = sum(!is.na(internal_time)))
lt <- xtable(t, caption = "Results of the BREQ 128-16 Standard Benchmark (see Section \\ref{sec:breq_exp}). For each row, there's a set \\(T\\) comprised by the times that \\textbf{algorithm} spent solving instances of size \\textbf{n}. We don't count the time of runs that ended in timeout. The meaning of the columns \\textbf{avg}, \\textbf{sd}, \\textbf{min}, \\textbf{max} and \\textbf{ter} are, respectively, the arithmetic mean of \\(T\\), the standard deviation of \\(T\\), the minimal value in \\(T\\), the maximal value in \\(T\\), and the cardinality of \\(T\\) (i.e. the number of runs that didn't end in timeout). The time unit of the table values is seconds.", label = 'tab:breq')
align(lt) <- c('r', 'c', rep('r', 5), 'c')
print(lt, hline.after=c(-1, 0), tabular.environment = "longtable", floating=F, add.to.row = list(pos = list(0), command = "\\hline \\endhead ")) 
@

\iffalse

\begin{landscape}
<<cut_table,echo=false,results=tex>>=
library(xtable)
library(dplyr)

cut <- read.csv("../data/cutstock_knap_solvers.csv", sep = ";")
cut$X <- NULL

mysummary <- function(t, alg) {
  t2 <- filter(t, algorithm == alg) %>%
    select(total_iter, hex_sum_knapsack_time, hex_sum_sort_time,
           hex_sum_master_prob_time)
  summary(t2)
}

lt <- xtable(mysummary(cut, 'ukp5_fp_cutstock'))
digits(lt) <- xdigits(2)
print(lt)
@
\end{landscape}
\fi
\clearpage

\section{Capítulo de resumo em português}

\subsection{Introdução}

O Problema da Mochila com Repetições (PMR) é uma variante dos conhecidos Problema da Mochila com Limite de Itens (PMLI) e Problema da Mochila 0-1 (PM 0-1).
A única diferença entre o PMR e essas outras duas variantes é que, no PMR, cada item possui uma quantidade de cópias ilimitada disponível.
O PMR é NP-difícil e, portanto, não existe um algoritmo que possa resolvê-lo em tempo polinomial.
%Entretanto, ele pode ser resolvido em tempo pseudo-polinomial usado a abordagem de programação dinâmica.
%O PMR também pode ser visto como um caso especial do PMLI no qual, para cada item distinto, existem mais cópias disponíveis do que o número máximo de cópias que cabe na mochila.

Instâncias do PMR são compostas pelo limite de peso \(c\) suportado pela mochila e um conjunto de \(n\) itens.
Cada item tem dois valores associados: seu peso e o seu lucro.
O objetivo do PMR é maximizar o lucro dos itens colocados dentro da mochila, enquanto respeitando o limite de peso da mochila.

A aplicação prática do PMR discutida nessa dissertação é: resolver os problemas de avaliação (\emph{pricing problem}) que são gerados quando se resolve a relaxação contínua de uma instância do \emph{Bin Packing Problem} (BPP) ou do \emph{Cutting Stock Problem} (CSP) usando a formulação de cobertura de conjuntos e a abordagem de geração de colunas.
O BPP e o CSP são problemas clássicos da área de pesquisa operacional e importantes para a indústria, vide~\cite{survey2014} e~\cite{gg-61,gg-63}.
Os melhores limites inferiores para a solução ótima desses dois problemas são os valores das soluções ótimas de suas relaxações contínuas.
A formulação do BPP/CSP com menos simetrias tem um número exponencial de colunas e, por causa disso, é resolvida usando a abordagem de geração de colunas~\cite{gg-61}.
Os problemas de avaliação gerados pela abordagem de geração de colunas (quando a mesma é aplicada ao BPP/CSP) são instâncias do PMR.

\subsection{Trabalhos relacionados}

Nesta seção é apresentada uma revisão bibliográfica sobre o PMR em ordem cronológica.

\begin{description}
\item[\cite{gg-61}] Uma aplicação prática do PMR é proposta. Essa aplicação é a resolução dos `problemas de avaliação' que surgem na resolução da relaxação contínua do BPP/CSP.
\item[\cite{gg-66}] São propostos algoritmos de programação dinâmica para o PMR no contexto dessa aplicação prática.
\item[\cite{mtu1}] Um algoritmo da abordagem \emph{branch-and-bound} é proposto, e comparado com algoritmos de programação dinâmica usando pequenas instâncias artificiais, onde obtem os melhores resultados, por uma pequena margem. 
\item[\cite{mtu2}] O foco muda para solucionar instâncias grandes em pouco tempo. Instâncias artificiais são usadas com esse propósito. No contexto dessas instâncias, os algoritmos de programação dinâmica são claramente dominados pelos algoritmos de \emph{branch-and-bound}.
\item[\cite{zhu_dominated}] É demonstrado que alguns desses conjuntos de instâncias artificiais possuem somente uma pequena quantidade de itens relevantes, esses conjuntos de instâncias são desacreditados.
\item[\cite{ukp_new_results}] Um novo algoritmo de programação dinâmica é proposto, assim como novas instâncias artificiais.
\item[\cite{eduk}] O novo algoritmo compara somente com algoritmos de \emph{branch-and-bound} e o algoritmo de programação dinâmica ingênuo, os antigos algoritmos de programação dinâmica não ingênuos foram esquecidos ou excluídos devido a experimentos anteriores.
\item[\cite{book_ukp_2004}] O novo algoritmo é considerado o estado da arte.
\item[\cite{pya}] O novo algoritmo de programação dinâmica é hibridizado com \emph{branch-and-bound}, e os conjuntos de dados são atualizados para serem mais difíceis. Estes conjuntos de dados são difíceis para \emph{branch-and-bound}, e o algoritmo híbrido compara somente com \emph{branch-and-bound}. O método híbrido é o novo estado da arte.
\item[\cite{sea2016}] Um algoritmo de programação dinâmica antigo é redescoberto e tem um desempenho melhor que o estado da arte quando executado sobre o conjunto de instâncias mais recente proposto.
\item[(essa dissertação)] Algoritmos antigos são revistos, reimplementados e testados. A influência dos conjuntos de instâncias e o contexto histórico se torna aparente.
\end{description}

\subsection{Classes de instâncias}

Esta seção trata das classes de instâncias usadas nos experimentos apresentados neste trabalho.
Essas instâncias são diferenciadas principalmente pela distribuição dos seus itens, ou seja qual a relação entre o peso e o lucro de cada item.
Neste trabalho não foram utilizadas instâncias com uma distribuição de itens sem correlação (peso e lucro de cada item escolhidos aleatoriamente), pois estas foram desacreditadas em \cite{zhu_dominated}.

\subsubsection{Instâncias do PYAsUKP}

O conjunto de instâncias proposto em~\cite{pya}, e reutilizado na comparação apresentada em~\cite{sea2016}, será referenciado como \emph{conjunto de instâncias do PYAsUKP}.
Estas são instâncias geradas artificialmente com o propósito de serem ``difíceis de resolver''.
O conjunto de instâncias usado neste trabalho é similar ao usado em~\cite{pya}.
A mesma ferramenta (PYAsUKP) foi usada para gerar os conjuntos de dados, e os mesmos parâmetros foram usados, com exceção das instâncias \emph{subset-sum}, que foram ampliadas multiplicando os seus parâmetros por dez.
Algumas instâncias fazem uso de sementes aleatórias que não foram publicadas, então as exatas instâncias usadas em~\cite{pya} podem ser diferentes.
As instâncias usadas aqui são exatamente as mesmas que foram usadas em~\cite{sea2016}.

O conjunto de instâncias do PYAsUKP é composto 4540 instâncias provenientes de cinco conjuntos de instâncias menores. Os cinco conjuntos menores são: \emph{subset-sum}, com \(10^3 \leq n \leq 10^4\) e \(5 \times 10^6 \leq c \leq 10^7\), totalizando 400 instâncias; \emph{strongly correlated}, com \(n = 10^4\) e \(2010000 \leq c \leq 10010000\), totalizando 240 instâncias; \emph{postponed periodicity}, com \(20000 \leq n \leq 50000\) e \(1020000 \leq c \leq 2 \times 10^6\), totalizando 800 instâncias; \emph{without collective dominance}, com \(5000 \leq n \leq 50000\) e \(105000 \leq c \leq 100050000\), totalizando 2000 instâncias; \emph{SAW}, com \(10^4 \leq n \leq 10^5\) e \(11000 \leq c \leq 10100000\), totalizando 1100 instâncias.

Em cada um desses cinco conjuntos menores de instâncias, para mesma combinação de parâmetros, o número de instâncias gerado é sempre perfeitamente divisível por dez.
Dessa forma, é possível definir um conjunto de instâncias composto de um décimo das instâncias do PYAsUKP (ou seja, 454 instâncias), e que possui pelo menos uma instância para cada combinação distinta de parâmetros usada.
Essa distribuição reduzida será referenciada como: \emph{o conjunto de instâncias reduzido do PYAsUKP}.

\subsubsection{Problemas de avaliação gerados a partir do BPP/CSP}

O \emph{Bin Packing Problem} (BPP) e o \emph{Cutting Stock Problem} (CSP) são problemas clássicos da área de pesquisa operacional.
Quando a relaxação contínua de uma instância do BPP/CSP é resolvida usando a formulação de cobertura de conjuntos e a abordagem de geração de colunas, são gerados de dezenas até milhares de `problemas de avaliação' (\emph{pricing problems}).
Cada um desses problemas de avaliação é uma instância do PMR.

Para uma mesma instância do BPP/CSP, o número de instâncias do PMR geradas, e o lucro dos itens em uma dada instância, pode variar baseado na escolha da solução ótima.
Uma instância do PMR pode ter múltiplas soluções ótimas, entretanto, somente uma delas é usada pela abordagem de geração de colunas, que define os próximos problemas de avaliação gerados.
Consequentemente, este conjunto de instâncias do PMR é difícil de descrever, ele possue um número grande e variável de instâncias com valores de lucro dos itens também variáveis.
A melhor forma encontrada pelo autor para garantir que os resultados são reproduzíveis é disponibilizando publicamente os códigos usados nos experimentos, conjuntamente com o conjunto de instâncias do BPP/CSP da literatura usado nos experimentos.
Os códigos são determinísticos e, consequentemente, irão produzir os mesmos resultados se executados várias vezes sobre a mesma instância.

Um \emph{survey} recente sobre o BPP e o CSP reuniu instâncias da literatura, e também propôs novas~\cite{survey2014}.
O número total de instâncias em todos conjuntos de instâncias apresentados no \emph{survey} é de 5692.
O autor dessa dissertação escolheu 10\% dessas instâncias para os experimentos realizados nesse trabalho.
Essa fração das instâncias foi escolhida aleatoriamente dentre instâncias do mesmo conjunto ou, em conjuntos maiores, dentre os mesmos parâmetros de geração.
As 596 instâncias do BPP/CSP selecionadas estão disponíveis no repositório GitHub do autor\footnote{As instâncias podem ser encontradas em \url{https://github.com/henriquebecker91/masters/tree/8367836344a2f615640757ffa49254758e99fe0a/data/selected_csp_inst}, e o código usado para resolver a relaxação pode ser encontrado no mesmo repositório (\url{https://github.com/henriquebecker91/masters/tree/8367836344a2f615640757ffa49254758e99fe0a/codes/cpp}).
O código pode ser compilado executando  \emph{make bin/cutstock} no diretório.
Infelizmente, o código pode ter dependências externas, e o usuário precisará instalar eles antes de ter sucesso na compilação.
As dependências são a biblioteca Boost C++ (veja: \url{http://www.boost.org/}), e o IBM ILOG CPLEX Studio 12.5 (veja: \url{https://www.ibm.com/developerworks/community/blogs/jfp/entry/cplex_studio_in_ibm_academic_initiative?lang=en}).
Os caminhos da biblioteca são configurados dentro do Makefile.}.

\subsubsection{Instâncias BREQ}

O \emph{Bottom Right Ellipse Quadrant} (abreviado como BREQ, e que pode ser traduzido como `Quadrante de Elipse Inferior Direito') é um tipo de distribuição de itens proposto pelo autor dessa dissertação.
O nome dessa distribuição é derivado do fato que, quando plotado em um gráfico (com o lucro e o peso como eixos x e y), os itens formam um quarto de elipse (especificamente, o quadrante inferior direito).
Essa distribuição foi criada para ilustrar que diferentes distribuições de itens favorecem diferentes abordagens e, consequentemente, a escolha de conjuntos de instâncias (ou especificamente, a distribuição dos itens) define o que é considerado o melhor algoritmo.

As instâncias BREQ favorecem algoritmos fazem uso de limites, como aqueles que fazem uso da abordagem \emph{branch-and-bound} (que pode ser traduzida literalmente como `ramificar-e-limitar').
Dessa forma, caso um conjunto de instâncias baseado no BREQ seja utilizado em uma comparação entre algoritmos de programação dinâmica e algoritmos de \emph{branch-and-bound}, os algoritmos de B\&B serão favorecidos.
Como veremos na seção de experimentos, muitas das instâncias do PYAsUKP levam muito mais tempo para serem solucionadas por algoritmos de B\&B do que por algoritmos de programação dinâmica.
Consequentemente, as conclusões sobre qual é o melhor algoritmo para o PMR seriam contrárias caso fossem somente usadas as instâncias do BREQ, do que se fossem usadas somente as instâncias do PYAsUKP.

O conjunto de instâncias utilizado na seção de experimentos consiste em um total de cem instâncias, dez instâncias para cada um dos dez valores de \(n\) utilizados: \(10^{11}\), \(10^{12}\), \(10^{13}\), \(10^{14}\), \(10^{15}\), \(10^{16}\), \(10^{17}\), \(10^{18}\), \(10^{19}\) e \(10^{20}\). A capacidade da mochila para uma determinada instância é \(128 \times n\).

\subsection{Abordagens e algoritmos}
\label{sec:alg_resumo}

As abordagens mais comuns usadas para solucionar o PMR são a programação dinâmica e o \emph{branch-and-bound} (B\&B).
A conversão de instâncias do PMR em instâncias de outras variantes do problema da mochila (PM 0-1 e PMLI) não é usada pois costuma resultar em perda de desempenho.

Algoritmos de programação dinâmica para o PMR tem um pior caso pseudo-polinomial de \(O\)(\(nc\)) (onde \(n\) é o número de itens, e \(c\) é a capacidade da mochila), e um uso de memória de \(O\)(\(n + c\)).
Os algoritmos de programação dinâmica (PD) que são usados nos experimentos são: UKP5 e EDUK.

O UKP5 foi proposto pelo autor dessa dissertação em \cite{sea2016}.
Após a publicação, o autor percebeu que o UKP5 era basicamente o mesmo algoritmo que o \emph{ordered step-off} apresentado em \cite{gg-66}.
O pseudo-código do UKP5/`\emph{ordered step-off}' pode ser encontrado no Algoritmo \ref{alg:ukp5} da Seção \ref{sec:ukp5}.

Algoritmos de B\&B para o PMR tem um pior caso exponencial, e um uso de memória de \(O\)(\(n\)).
Os algoritmos de B\&B que são usados nos experimentos são: MTU1 e MTU2.
Alguns algoritmos combinam ambas abordagens (PD e B\&B). 
Os algoritmos híbridos que são usados nos experimentos são: EDUK2 e GREENDP.

Os seguintes algoritmos foram implementados em C++ pelo autor desse trabalho para realização de experimentos: UKP5, MTU1, MTU2 e GREENDP.
Os seguintes algoritmos já possuiam uma implementação disponível publicamente: EDUK (OCaml), EDUK2 (OCaml), MTU1 (Fortran77) e MTU2 (Fortran77).

\subsection{Experimentos e análise}

Cinco experimentos são apresentados nessa seção.
O primeiro experimento consistiu na execução de UKP5, EDUK2, e GREENDP sobre o conjunto de instâncias do PYAsUKP.
O maior tempo que o UKP5 dispendeu em uma única instância foi 20 segundos.
O GREENDP teve resultados similares ao UKP5, usando significativamente mais tempo em algumas instâncias e marginalmente menos tempo em outras.
O maior tempo que o MGREENDP dispendeu em uma única instância foi 43 segundos.
O PYAsUKP dispendeu consideravelmente mais tempo do que o UKP5 e o MGREENDP em cada conjunto de instâncias.
Na maioria dos conjuntos de instâncias, o PYAsUKP dispendeu pelo menos dez vezes mais tempo que o UKP5 ou o MGREENDP.
O maior tempo que o PYAsUKP dispendeu em uma única instância foi 416 segundos.
Para mais informações, consultar a tabela \ref{tab:times_pya} que se encontra nesse apêndice.

O segundo experimento consistiu na execução de MTU1 (C++), MTU2 (C++), MTU1 (Fortran77) e MTU2 (Fortran77) sobre o conjunto de instâncias reduzido do PYAsUKP (454 instâncias).
A implementação original em Fortran foi comparada com a implementação do autor dessa dissertação em C++.
Considerando o conjunto de instâncias utilizado, ambos algoritmos (em ambas implementações) não são competitivos com os algoritmos de PD e híbridos previamente testados (UKP5, MGREENDP e PYAsUKP) em relação ao tempo de execução.
Todas as quatro implementações falharam em resolver cerca de metade das instâncias antes do limite de tempo de 1000 segundos por instância.
Entre as implementações do MTU1 (C++ e Fortran) não há diferença significativa.
Entre as implementações do MTU2, pela forma como foi implementada a ordenação dos itens, a implementação em C++ usa menos tempo, em especial para instâncias do tipo \emph{subset-sum}.
Para mais informações, consultar a tabela \ref{tab:times_mtu} que se encontra nesse apêndice.

O terceiro experimento consiste na execução de todos os algoritmos mencionados na Seção \ref{sec:alg_resumo} sobre as cem instâncias do \emph{BREQ 128-16 Standard Benchmark}. 
Os resultados demonstram que algoritmos de B\&B, ou que possuem cálculo de limites (\emph{bounds}), tem ampla vantagem sobre algoritmos que utilizam unicamente programação dinâmica, considerando somente esse conjunto de instâncias.
Isso corrobora o argumento de que a escolha de instâncias define o que é considerado o melhor algoritmo.
Os resultados desse experimento podem ser visualizados na figura \ref{fig:breq_bench}.
Para mais informações, consultar a tabela \ref{tab:breq} que se encontra nesse apêndice.

O quarto experimento consiste na execução do UKP5, MTU1 e o CPLEX para solucionar os problemas de avaliação gerados a partir de instâncias do BPP/CSP.
Os resultados mostram que o CPLEX não é competitivo para solução dos problemas de avaliação.
Quando o MTU1 e o UKP5 são usados para solucionar os problemas de avaliação, para a maioria das instâncias, solucionar todos os problemas de avaliação de uma determinada instância do BPP/CSP toma menos de um segundo.
Cerca de cinquenta instâncias do conjunto de instâncias do BPP/CSP exigem mais do que um segundo para que o UKP5 solucione todos os problemas de avaliação gerados pela instância (até um máximo de 50 segundos em uma das instâncias).
Quando o CPLEX e o MTU1 são usados para solucionar os problemas de avaliação dessas cinquenta instâncias mais difíceis, cada uma dessas instâncias excede o limite de tempo de dez minutos por instância do BPP/CSP.

O quinto experimento consiste na execução do UKP5 e do PYAsUKP (EDUK2) em dois computadores com diferentes quantidades de cache compartilhada, de forma serial e paralela, sobre a versão reduzida do conjunto de instâncias do PYAsUKP (454 instâncias).
O paralelismo aqui citado se refere a execuções independentes (i.e. sobre diferentes instâncias), em cores isolados, com o propósito de reduzir o tempo necessário para realizar um \emph{benchmark}.
Os resultados mostram que as execuções em paralelo tomam mais tempo que as execuções seriais (comparando cada execução paralela com a serial correspondente).
Isto indica que mesmo em \emph{cores} isolados, a execução concorrente afeta os tempos de execução.
O UKP5 é mais afetado por esse efeito que o PYAsUKP, o que atribuímos ao maior uso de memória e, consequentemente, maior disputa pela cache compartilhada.
Todos os experimentos descritos anteriormente foram executados de forma serial, para evitar esse ruído.

\subsection{Conclusões}

A análise crítica da literatura, conjuntamente com o resultado dos experimentos apresentados nesse trabalho, leva a crer que a escolha de instâncias e algoritmos usados nos experimentos de trabalhos anteriores permitiu que um algoritmo antigo, porém eficiente, fosse esquecido pela comunidade científica.  
Este algoritmo é o \emph{ordered step-off} que é implementado, com pequenas alterações, pelo UKP5.

Outras contribuições são o conceito de dominância de solução (fraca e forte), que é utilizado pelo \emph{ordered step-off} mas não havia sido conceitualizado.
Além da evidência trazidas pelos experimentos de que: o pior caso do B\&B pode ocorrer em problemas de avaliação (\emph{pricing problems}); a escolha entre soluções ótimas para um problema de avaliação altera consideravelmente o número de problemas de avaliação gerados subsequentemente (para uma mesma instância do BPP/CSP); algoritmos do PMR que fazem uso intensivo da memória apresentam alteração nos tempos quando executados concorrentemente porém em \emph{cores} isolados; a conversão do lucro dos problemas de avaliação de ponto flutuante para inteiro não causa perda significativa no valor da solução ótima da instância do BPP/CSP subjacente. 

