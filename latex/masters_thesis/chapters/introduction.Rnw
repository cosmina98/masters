\chapter{Introduction}

The unbounded knapsack problem (UKP) is a simpler variant of the well-known bounded knapsack problem (BKP) and the 0-1 Knapsack Problem (0-1 KP).
The only difference between UKP and these other two knapsack problems is that UKP don't impose a bound in the available quantity of each item type.
The UKP can also be seen as an special case of the BKP where, for each item type, there's more copies available than is possible to fit in the knapsack capacity.

The UKP is NP-Hard, and thus has no known polynomial-time algorithm for solving it. 
However, it can be solved in pseudo-polynomial time by using the dynamic programming approach. 

\section{Motivation and Scope}
\label{sec:motivation}

%It's a simpler variant of one of the most classical computer science problems.
The unbounded knapsack problem has theoretical and applied uses.
There's many examples in the literature of using the UKP to test novel solving approaches as \cite{mtu1}, \cite{on_equivalent_greenberg}, \cite{pya}, and \cite{DP_inequalities}. % the last is the article from xuequi he, that don't compete with state of the art butonly try new approach
Such interest is commonly found in well-known, easy to understand and model, NP-hard problems with pratical everyday uses, as is the case of the UKP and other KPs. Recently, the 0-1 KP was used to study how humans solve NP-Hard problems \cite{humans_solve_complex}.
The author finds the use of UKP (or any other problem) for testing experimental approaches a necessary and relevant line of research. However, the author has a critical view about the performance comparison of algorithms over artificial instances that don't model any real-world item's distribution.

% CHECAR COM BURIOL
% ``surrogate relaxation of IP problems with non-negative coefficients'' PISINGER p. 147 motivation
%The applied uses of the UKP are related to logistics.
%Also, instances of the BKP or 0-1 KP where there's more copies of each item than ethy can be fit in the knapsack should be solved as UKP, as UKP has some properties that can be exploited for speeding-up the computation that don't exist in BKP and 0-1 KP.

The applied use of UKP that this work will focus is: the UKP as the pricing subproblem generated by solving the continuous relaxation of the set covering formulation for the unidimensional Bin Packing Problem (BPP) and Cutting Stock Problem (CSP) using the column generation approach.
The BPP and the CSP are classical problems in the area of operations research and of great importance for the industry, see \cite{survey2014} and \cite{gg-61,gg-63}.
The best bound known for the optimal solution value of those two problems is the optimal solution of the exact resolution of their continuous relaxation.
The tightest formulation for BPP and CSP has an exponential number of columns and because of this, is solved using the column generation approach \cite{gg-61}. The UKP is the pricing subproblem of this column generation approach.

The lower bound provided by the continuous relaxation of those two minimization problems is so tight that was speculated that \emph{rounding-up the relaxation's optimal value would always give the optimal value of the original problem} \cite{survey2014}. The BPP and CSP instances for which the previous statement is true are said to have the Integer Round-Up Property (IRUP). The conjecture that all BPP and CSP instances had the IRUP property was proven false. However, non-IRUP instances were artificially created with this intent. Also, to the author's knowledge, no BPP or CSP instance proved false the conjecture that all BPP and CSP instances have the Modified Integer Round-Up Property (MIRUP). If an instance of the BPP or CSP has the MIRUP, the rounding up of the relaxation's optimal value will be, at max, one unity smaller than the optimal value of the original problem.

The author acknowledges the existence of many very good heuristics and approximations for solving the UKP\footnote{Including the existence of fully polynomial time approximation schemes (FPTAS) for UKP.}. However, the focus of this work is exact methods. This focus will be divided between: the study of the exact algorithms proposed in the literature, and the instance datasets used to compare them; the UKP in the context of the CSP and BPP problems.

The IRUP and MIRUP properties cited above are found in the exact solution of the continuous relaxation of BPP and CSP. The use of an approximation or heuristic to solve the pricing problem would make the relaxation's solving not exact. A study of the effects of using an approximation algorithm to solve the pricing problem would be interesting, but is not in the scope of this work. It's interesting to rememeber that if the relaxation isn't solved exactly, a B\&B method that used the relaxation as an lower bound wouldn't be exact too.

\section{Formulation and Notation}
\label{sec:formulation}

%Say solution is a multiset, will be used in the dominance section below
%Say that we consider items with the same weight and profit the same item

The notation presented at this section will used for the ramainder of this work.
An instance of the UKP is a pair of a capacity \(c\) and a list of \(n\) items.
Each item can be referenced by its index in the item list \(i \in \{1\dots n\}\).
Each item \(i\) has a weight value \(w_i\), and a profit value \(p_i\).
A solution is an item multiset (i.e, a set that allows multiple copies of the same element).
The sum of the items' weight, or profit value, of a solution \(s\) is denoted by \(w_s\), or \(p_s\); and will be refered as the weight, or profit, of the solution.
A valid solution \(s\) has \(w_s \leq c\).
An optimal solution \(s^*\) is a valid solution with the greatest profit among all valid solutions.

To solve an instance of the UKP is to find an optimal solution for that instance. Finding all optimal solutions for an instance of the UKP isn't the focus of this work. However, the existence of multiple optimal solutions and the effects of this fact are fully acknowleged.
%We refer to the profit value shared among all optimal solutions for a capacity \(y\) as \(opt(y)\), if we omit the capacity then \(c\) is implied.

The mathematical formulation of UKP is:

\begin{align}
  maximize &\sum_{i=1}^n p_i x_i\label{eq:objfun}\\
subject~to &\sum_{i=1}^n w_i x_i \leq c\label{eq:capcons}\\
            &x_i \in \mathbb{N}_0\label{eq:x_integer}
\end{align}

%\footnote{If the quantities weren't restricted to the integers the problem wouldn't be NP-Hard.}
The quantities of each item \(i\) in an optimal solution are denoted by \(x_i\), and are restricted to the non-negative integers, as~\eqref{eq:x_integer} indicates. 
We assume that the capacity \(c\), the quantity of items \(n\) and the weights of the items \(w_i\) are positive integers. 
The profit values of the items \(p_i\) are positive real numbers.

%\footnote{If the efficiencies tie the best item is the item with the lowest weight between the tied items.}
The terms \emph{item} and \emph{item type} mean two different things in this work.  The term \emph{item} will be used to refer to an specific item, that has a position in the items' list of an instance, and that can have duplicates in the same instance. The term \emph{item type} will be used to refer to a pair of weight and profit value, that can be shared by many items (in the same instances, or different ones).

The efficiency of an item \(i\) is its profit-to-weight ratio (\(\frac{p_i}{w_i}\)), and is denoted by \(e_i\). 
We use \(w_{min}\), or \(w_{max}\), to denote the smallest items' weight, or the biggest items' weight, within an instance of the UKP.
We refer to the item with greatest efficiency among all items of an specific instance as the \emph{best item} (or simply \(b\)); if more than one item share the greatest efficiency, then the item with the lowest weight among them will be considered the best item type; if more than an item has both both previously stated characteristics, then the first item with both characteristics in the items' list is the best item.
%Also, the item type with the lowest weight among all item types will be refered as the \emph{smallest item}.

%If two or more items have the same weight, we ignore all but the one with the best profit (the others can be discarded without loss to the optimal solution value). The analogue is valid for items with the same profit. Consequently, any two distinct items will always have different weight and profit (only their efficiency can be the same). Items that share the same weight (or profit) can be removed by sorting (\(O(n \times log(n))\)). Ignoring such items simplify the proofs, and don't change the UKP significantly.

The observant reader will perceive that an UKP instance is defined by a list of items, instead of a set of items, as usual. Some algorithms sort the items and manipulate their indexes. So having notation to refer to the item's indexes is convenient. Also, a set would not allow for identical items (i.e. that share the same item type). Such duplicated items exist in some instance datasets of the literature, and can affect the timing of algorithms. %As we don't allow distinct items with the same weight and profit, the difference between a list and a set, for the problem formulation, is null.

\section{Well-known properties of UKP}

In this section, we will see well-known properties of the UKP that can be exploited to speed-up computation. The main point of those properties is that they are only valid if we have available as many copies of each item type as we could need. Consequently, those properties are always valid for UKP and generally not valid for other knapsack variants. However, it's interesting to note that, if a BKP or 0-1 KP has as many or more copies of some item type than it can fit in the knapsack, then we have an unbounded quantity of that item type available and the properties described below apply to these item types. If every item type \(i\) of an instance of the BKP (or 0-1 KP) have at least \(\floor{\frac{c}{w_i}}\) copies available, then the instance can be solved as it was an instance of the UKP.

\subsection{Dominance relations}

If one item \(i\) has the same or less weight than another item \(j\), and \(i\) also has the same or more profit value than item \(j\), then it's clear that if we replace \(j\) by \(i\) in any valid solution, the solution will remain valid (the weight of the solution can only remain the same or decrease), and the profit value of the solution can only remain the same or increases. This relationship between \(i\) and \(j\) is called a dominance relation; more specifically, we can say that \(i\) dominates \(j\). %It's important to note that, as UKP don't limit the quantity of each item type in a solution, we can always do these replacements (what's not true for other KP variants).

Let's suppose that \(i\) dominates \(j\). There's only two possibilities: the profit value of \(i\) is greater than the profit value of \(j\); or they are the same. If it's the former, then \(j\) can't be part of an optimal solution. By definition, an optimal solution is a valid solution with the greatest profit value; if \(j\) was part of an optimal solution, replacing \(j\) by \(i\) would give an also valid solution with an even greater profit value (\emph{reductio ad absurdum}). If it's the latter (i.e. \(i\) and \(j\) have the same profit value), \(j\) can be part of an optimal solution. However, we would get an optimal solution with the same or less weight, by replacing \(j\) by \(i\) in the optimal solution.

If we are interested in obtaining one optimal solution, but not all optimal solutions, we can use dominance relations to reduce the computational effort needed to find a solution. This is done by detecting dominance relations, and removing the dominated items, thus reducing the size of the problem. The detection can be done in a preprocessing phase by an algorithm specific for dominance detection, or within the solving algorithm (reusing computation that it would need to done anyway). Both approachs have upsides and downsides, some of them will be discussed further in this work.

Dominance relations become more interesting after we perceive that they can be apllied to item multisets (solutions or parts of solutions), and not only to individual items. As UKP don't limit the quantity of each item type in a solution, we can treat any solution as a new item type, with weight and profit value equal to the weight and profit value of the solution.

If a solution \(s\) dominates an item \(j\), we have the same properties that if \(s\) was an item. Whenever we would use \(j\), we can use the items that comprise \(s\) in place of \(j\). In the literature, such dominance relation is called \emph{collective dominance}. Special cases of the collective dominance are the \emph{multiple and simple} dominances. Our example could be regarded as simple dominance if \(s\) was comprised of one single copy of one item (as the first example of this section); and could be regarded as multiple dominance if \(s\) was comprised of multiple copies of the same item (without any other item types). Simple dominance can be seen as a special case of multiple dominance, and some authors use `multiple dominance' to refer to both \cite{pya}.

If a solution \(s\) dominates a solution \(t\), and \(t\) is comprised only of copies of the same item, we have what is called in the literature of \emph{threshold dominance}. If \(t\) is made of \(n\) copies of item \(j\), then we know that we can diregard solutions with \(n\) or more copies of item \(j\) (as each group of \(n\) copies of \(j\) can be replaced by \(s\) without loss). Depending on the solving algorithm structure, this can mean that at some point, the item can be excluded from a global item list (reducing the further computational effort of the algorithm). Collective dominance can be seen as a special case of threshold dominance, where \(n = 1\) (i.e. the dominated solution \(t\) is a single item solution).

The simple and multiple dominances were deeply studied, and algorithms that remove all simple and multiple dominated items in \(O(n^2)\), as heuristics with less complexity that don't guarantee removing all dominated items, were proposed\footnote{See \cite{pisinger_thesis} for a good revision about this subject.}. In the other hand, the collective and threshold dominance seems too computationally expensive to be done outside a DP algorithm, where the optimal solutions of lower capacities can be reused to detect collective and threshold dominance \cite{pya}.

The EDUK and EDUK2 algorithms integrate and make use of these four dominances. In fact, threshold dominance was discovered by the EDUK creators in \cite{eduk}, and was the EDUK algorithm main feature. However, we will see that both algorithms seem to be dominated by algorithms that predate them by about forty years, as the \emph{ordered step-off} from \cite{gg-66}, and its `improved version' from \cite{green_improv}. Algorithms that didn't directly made use of any of those dominances.

A closer look to those old algorithms reveal that they indirectly make use of all four dominances. What the author wants to say by this is that: the old algorithms will eventually stop using dominated items to generate new solutions in the course of the algorithm execution. However, this is only one way to see it. The approach used by those old algorithms is focused in solutions, not individual items. Would be more adequate to say that they make use of some sort of \emph{solution dominance}. Ideally, if solution \(s\) dominates solution \(t\) (where both solutions can be comprised of any items), then an optimized algorithm would not generate any solutions that are a superset of \(t\) (as the respective supersets of \(s\) would dominate them anyway). Such dominance would generalize all previous dominances, as the dominated items can be seen as dominated single item solutions (or multiple item solutions, in the case of threshold dominance).

Those old algorithms don't apply this ideal solution dominance, but a weaker version of it. This weaker version of solution dominance don't avoid generating every solution that is a superset from a dominated solution, but can be implemented without almost any overhead. As it's very algorithm specific, it will be further discussed at the algorithms section, specifically Section \ref{sec:ukp5_sol_dom_expl}.

In this section, the concept of dominance was introduced by the explanation of the four most well-known dominance relations and the idea of solution dominance. In the literature, one of the definitions used for dominance is: ``Given an instance of UKP, relative to item types set \(N\), item type \(k \in N\) is dominated if the optimal solution value does no change when \(k\) is removed from \(N\).'' \cite[p. 100]{martello_book}. Simple, multiple and collective dominance are consistent with this definition. However, if an item is threshold dominated, it can yet be present in all optimal solutions (only in a bounded quantity). Solution dominance isn't covered by this definition, as it's item-centric.

\subsection{Periodicity and periodicity bounds}

%The UKP has an obvious periodic property that for every knapsack capacity that is a multiple of the best item's weight, the optimal solution for that knapsack capacity is \(\frac{c}{w_b}\) copies of the best item (it's clearly the most efficient use that can be made of such capacity). The UKP has also a not-so-obvious and more interesting periodic property that states that:
The UKP has an interesting periodic property that can be stated in the following way: for every set of item types, there exists a capacity \(y\), for which every capacity \(y'\) (\(y' > y\)) will have an optimal solution that is an optimal solution for capacity \(y' - w_b\) with one more copy of the best item added. In other words, after some capacity \(y\), we can find optimal solutions simply by adding copies of the best item to optimal solutions of capacities \(y\) and lower (all other items aren't relevant anymore). We will call this periodic property: \emph{periodicity}. Should be clear that, if we knew \(y\) beforehand, and \(y < c\), then we can solve UKP for the capacity \(y^{*} = c - \ceil{\frac{c - y}{w_b}}w_b\) and fill the gap between \(y^{*}\) and \(c\) with exactly \(\frac{c - y^{*}}{w_b}\) copies of the best item (instead of solving UKP until the capacity \(c\)).
%The focus of this section will be this second periodic property, that we will call simply by `periodicity'.

The periodicity is a direct consequence of the threshold dominance. However, the periodicity was discovered much before the concept of threshold dominance. For instance, periodicity was already described in \cite{gg-66}. As the concept of threshold dominance was already explained in this work, the author will use it to explain periodicity.

The threshold dominance property states that, if solution \(s\) dominates solution \(t\), and \(t\) contains only \(n\) copies of the same item type \(j\), then solutions with \(n\) or more copies of \(j\) can be be replaced by solutions using \(s\) instead (without loss).
The periodicity states that after some capacity \(y\) we can obtain optimal solutions only by adding copies of the best item to the optimal solutions from capacities below \(y\) (all other items aren't relevant anymore).
The link between these two properties is that \emph{for a sufficient big capacity, solutions comprised of copies of the best item will threshold dominate solutions comprised of copies of any other item}.

First let's verify the truth of the statement above. For any two positive integers \(a\) and \(b\) there will always exist at least one integer number that it's divisible by both \(a\) and \(b\) (e.g. \(a \times b\), or their \emph{lowest common multiple}, \(LCM(a, b)\)). Therefore, for each non-best item \(j\), there will exist a capacity value \(y\) that it's divisible by both \(w_b\) and \(w_j\). Given \(m_j = \frac{y}{w_b}\) and \(n_j = \frac{y}{w_j}\), and by the definition of best item, we have that \(m_j \times p_b \geq n_j \times p_j\). In other words, a solution comprised only of \(m_j\) copies of the best item will threshold dominate a solution comprised only of \(n_j\) copies of item \(j\).

It's important to note that, in the case of an instance where all items have the same efficiency, the best item (that will have weight \(w_{min}\) by definition) will treshold dominate each other item at the capacity that is the \emph{lowest common multiple} between their weights (as shown in the last paragraph). However, if the best item \(b\) is more efficient than the non-best item \(j\) (what's much more common), then a smaller solution \(s\) comprised only of copies of \(b\) can be more profitable than a bigger solution \(t\) comprised only of copies of \(j\). The weight of the two solutions don't have do be the same.

Now let's explain how periodicity is a direct consequence threshold dominance. As we have seen, for each non-best item \(j\), there will exist a positive integer \(n_j\), in a way that solutions with \(n_j\) copies of \(j\) are dominated by solutions that use \(m_j\) copies of \(b\) instead. Let's say that exists a solution \(u\) comprised of \(n_j - 1\) copies of each item \(j\). If another copy of any item \(j\) is added to \(u\), the resulting solution \(u' = \cup \{j\}\) could be replaced by another solution \(v\) that contained no copies of \(j\), and \(m_j\) additional copies of \(b\). Any solution that weights more than solution \(u\) has only two possibilities: it uses more copies of the best item; or it uses more than \(n_j\) copies of some non-best item \(j\), in which case, copies of \(j\) can be replaced by copies of \(b\) until the quantity of copies of \(j\) is smaller than \(n_j\). Consequently, after the knapsack capacity \(y'' = w_u\), adding copies of other items to a solution would equal to adding copies of the best item (making any other item type except \(b\) irrelevant). Note that \(y''\) is only an \emph{upper bound} on \(y\), the value of \(y\) can be smaller than \(y''\), as the items that the best item threshold dominate, can themselves threshold dominate other items.

It's important to note that computing the exact value of \(y\) is a very expensive process that equals to solving UKP for all capacities \(y\) and lower while checking for threshold dominance. None of the algorithms that the author's has knowledge computes the exact value of \(y\) before starting to solve the UKP. The algorithms compute an \emph{upper bound} on the \(y\) capacity value, as the one presented in last paragraph, that's basically the Kellerer's bound \cite{book_ukp_2004}.
% XXX TODO: verify the kellerer's bound in the book

An upper bound on \(y\) is less valuable than \(y\) itself, but it can be computed in a reasonable polynomial time, before starting the solving process. If one algorithm checks for threshold dominance periodically, it can stop when all non-best items have been threshold dominated by the best item. Such algorithm would not benefit much from computing an upper bound on the \(y\) capacity value. If this algorithm setup phase (e.g. allocating and initializing memory) is linear to the knapsack's capacity \(c\) and the upper bound on the \(y\) capacity value is considerably smaller, then the algorithm could benefit from the upper bound. 

There exist many proposed periodicity bounds, but some are time consuming, as the \(O(n^2)\) periodicity bound presented in \cite{badbound1}, others depend on specific instance characteristics to be tight, as \cite{badbound2} and \cite{pya}. For reasons that will be made clear in the conclusions, the author didn't found relevant to present a revision on periodicity bounds in this work. The UKP5 algorithm makes use of one simple periodicity bound, and it will be explained together with the algorithm in Section \ref{sec:ukp5_periodicity}.

