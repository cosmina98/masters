\section{Conclusions}

%However, the instances were too small to draw strong conclusions, and the relative difference between G.G. and MTU1 average times was not even one order of magnitude apart.
%The G.G. algorithm was about four times slower than MTU1 in the instances with~\(n = 25\); about two or three times slower in the instances with~\(n = 50\); and less than two times slower in instances with~\(n = 100\).
%This trend could indicate that for big instances, the G.G. algorithm would have better times than MTU1 (e.g. the G.G. algorithm could have a costly initialization process but a better average-case asymptotic complexity).
%The B\&B approach was established in the seventies as the most efficient approach for solving the UKP, what is greatly a consequence of the datasets, items distributions, and generation parameters used at the time.
%The author of this thesis believes that this claim was first made in~\cite{mtu2}, and then other papers as~\cite{babayev} began repeating it.
%The fact that only the code for MTU1 and MTU2 was readily available also did not help the situation, as some began to claim that MTU2 was the \emph{de facto} standard algorithm for the UKP, see~\cite{ukp_new_results}.

% TODO: maybe add to discussions?
\begin{comment}
\subsubsection{Weak solution dominance}
\label{sec:ukp5_sol_dom_expl}

% TODO: ADD THIS SOMEPLACE ELSE
In this section we will give a more detailed explanation of the workings of the previously cited weak solution dominance.
We use the notation~\(min_{ix}(s)\) to refer to the lowest index among the items that compose the solution~\(s\).
The notation~\(max_{ix}(s)\) has analogue meaning.

When a solution~\(t\) is pruned because~\(s\) dominates~\(t\) (lines~\ref{if_less_than_opt_begin} to~\ref{if_less_than_opt_end}), some solutions~\(u\), where~\(t \subset u\), are not generated. 
If~\(s\) dominates~\(t\), and~\(t \subset u\), and~\(max_{ix}(u - t) \leq min_{ix}(t)\), then~\(u\) is not generated by UKP5. 
For example, if~\(\{3, 2\}\) is dominated, then~\(\{3, 2, 2\}\) and~\(\{3, 2, 1\}\) will never be generated by UKP5, but~\(\{3,2,3\}\) or~\(\{3,2,5\}\) could yet be generated (note that, in reality, it is the equivalent~\([3,3,2]\) and~\([5,3,2]\) that could yet be generated).
Ideally, any~\(u\) where~\(t \subset u\) should not be generated as it will be dominated by a solution~\(u'\) where~\(s \subset u'\) anyway. 
It is interesting to note that this happens eventually, as any~\(t \cap \{i\}\) where~\(i > min_{ix}(t)\) will be dominated by~\(s \cap \{i\}\) (or by a solution that dominates~\(s \cap \{i\}\)), and at some point no solution that is a superset of~\(t\) will be generated anymore.

\subsubsection{Implementation details}
\label{sec:ukp5_periodicity}

With the purpose of making the initial explanation simpler, we have omitted some steps that are relevant to the algorithm performance, but not essential for assessing its correctness. 
A complete overview of the omitted steps is presented in this section.

\end{comment}


\emph{An algorithm is dominated by other in the context of a dataset.}
An example presented in this thesis is MTU2.
MTU2 is the best algorithm between eight algorithms for one dataset (see Section \ref{sec:breq_exp}), and is not competitive for other five datasets (see Section \ref{sec:pya_exp}).
The literature review, and the further discussion of instance datasets and solving approaches, have shown \emph{how the choice of datasets defined the best algorithm through the last fifty years}.

It is worth mentioning that, taking into account the historical context, the choices made by previous researchers were sound and reasonable.
Despite this, an efficient DP algorithm was ignored for decades when it was relevant for the comparisons and experiments realized.

\emph{the bibliographical research is important, and should be followed by a reevaluation of the evidence chain.}

\section{UKP-specific knowledge contributions}

An outline of the UKP-specific knowledge contributions follows. It is ordered by the level of importance the author gives to them.
\begin{enumerate}
\item The knowledge that an old DP algorithm outperforms a state-of-the-art hybrid algorithm, in the most recent benchmark dataset.
\item The concept of solution dominance, and its implications for periodicity bounds and the four previously established dominance relations.
\item Evidence that the B\&B approach worst-case can arise when solving pricing subproblems of BPP/CSP.
%\item Evidence that variations in the optimal solution returned by the pricing problem solver can have a strong effect in the number of pricing problems generated.
%\item Evidence that UKP algorithms that are memory intensive should be executed serially for comparison.
\item Evidence that converting the pricing problem profit values to large integers do not cause significant loss.
\end{enumerate}

The author believes that the first contribution is already well exposed, either in Section \ref{sec:pya_exp}, or in \cite{sea2016}.
The technical details of the second contribution (i.e. the concept of solution dominance) were already discussed (see Section \ref{sec:ukp5_sol_dom_expl}), but not how it impacts the previous techniques described in the literature.
The weak solution dominance reduces the further improvement that can be found by applying the four dominance relations and/or periodicity bounds in the same algorithm.
The weak solution dominance and the four dominance relations are two different ways of dealing with the same task.
The first involves keeping an index in each solution to mark which items can still be added to the solution.
The second involves keeping a global list of undominated items, 
%Applying one of the approaches reduce how much the other can further improve the algorithm.

The approach used by EDUK gives a strong guarantee that any dominated item will be discarded and never used again.
However, the weak solution dominance described in Section \ref{sec:ukp5} is implemented with almost no overhead, and seems to have a very similar impact in the removal of dominated items/solutions.
One could argue that EDUK can be at disadvantage for being implemented in a functional language, or that better implementations of the algorithm could be written, the author can not refute such claims.
Maybe new implementations of the EDUK approach can show the superiority of applying the four dominances in the EDUK fashion.
However, for the tested datasets, the weak solution dominance approach seems to be the most efficient one.

The periodicity check exists both in algorithms like EDUK/EDUK2 and the old terminating step-off.
In EDUK/EDUK2 it is a consequence of applying all four dominances repeatedly, and in the terminating step-off it is a consequence of applying weak solution dominance.
A periodicity check can save effort by stopping the computation at a capacity~\(y < c\).
However, in all algorithms that implement the periodicity check, when this early termination happens, it is because the only item that could possibly be used is the best item.
Consequently, in each one of these last positions (between \(y\) and \(c\)), the algorithm would not execute \(O(n)\) steps anymore, but only \(O(1)\) steps.
The periodicity check only saves the effort of iterating these last \(c - y\) positions.
It is a minor improvement over the application of weak solution dominance, or the application of the four item dominances.

The periodicity check (and, by consequence, the dominances) also reduces the utility of periodicity bounds.
If an upper bound on \(y^+\) could be used to stop the computation before it reaches capacity \(c\), then the periodicity check would stop the computation even before the capacity predicted by the upper bound (with slightly more overhead).
In an algorithm with periodicity checking, the utility of upper bounds on the periodicity capacity~\(y^+\) is restricted to saving memory and saving the time spent initializing such saved memory.
Note that some algorithms would not even have such benefits, as they do not allocate or initialize the memory in advance.

The evidence that constitutes the third knowledge contribution can be found in Section \ref{sec:csp_experiments}.
In the majority of the instances, the time spent by both the B\&B and DP approaches when solving pricing problems was significantly smaller than the times solving the master problems of the same instance.
Nevertheless, for some instances, the B\&B approach has presented its worst-case behavior and, in these instances, more time was spent solving pricing subproblems then solving the master problem.

While the following quote was written in the context of the 0-1 KP, the author found it relevant to complement what was just said: ``Dynamic programming is one of our best approaches for solving difficult (KP), since this is the only solution method which gives us a worst-case guarantee on the running time, independently on whether the upper bounding tests will work well.''~\cite[p.~13]{where_hard}.

\section{Future work}
\label{sec:future_works}

\begin{itemize}
\item How similar are the datasets of the UKP and the BPP/CSP presented in the literature to the ones existent in the real-world?
\item Do the instances found in the real-world benefit some approaches over others?
\item Would a hybrid algorithm based on the `terminating step-off' and MTU2 present the same level of improvement that EDUK2 has over EDUK?
\item What would be the pratical performance of an implementation of the algorithm described in \cite{babayev}?
\item How do the traits of the optimal solution for the pricing subproblem affect the master problem? Does always returning an optimal solution with minimal weight has a negative effect? What about adding all patterns that improve the master problem solution, and not only the best pattern (i.e. optimal solution)?
\item Are the profit values (and, consequently, the items distributions) of the pricing subproblems uniform between similar BPP/CSP instances, and/or the same BPP/CSP instance? Is it possible that they converge to a specific distribution at each iteration of the column generation?
\item WOULD B\&B ALGORITHMS THAT WEREN'T DEEP FIRST DISPLAY THE SAME PROBLEMS?
\end{itemize}

\subsection{Acknowledgements}

PUT HERE ACKNOWLEDGMENT TO CNPQ, MAYBE PROJECT, POIRREZ

