\section{Introduction}
\label{sec:introduction}

The objective of this work is to provide an extensive comparison of the exact algorithms for solving the Unbounded Knapsack Problem (UKP).
The UKP is similar to the Bounded Knapsack Problem (BKP) and the 0-1 Knapsack Problem (0-1 KP).
The only difference between the UKP and the BKP (or the 0-1 KP) is that the UKP has an unlimited quantity of each item available.
The UKP is a weakly NP-Hard problem, as are the BKP and the 0-1 KP.
%The UKP can also be seen as a special case of the BKP in which, for each item type, there are more copies available than is possible to fit in the knapsack capacity.

The UKP is the pricing subproblem generated by solving the continuous relaxation of the set covering formulation for the unidimensional Bin Packing Problem (BPP) and Cutting Stock Problem (CSP) using the column generation approach\cite{gg-61,gg-63}.
The BPP and the CSP are classical problems in the area of operations research\cite{survey2014}.
The best lower bounds known for the optimal solution value of the BPP and the CSP are the optimal solution value for their continuous relaxations.
The tightest formulation for the BPP and the CSP has an exponential number of columns and, because of this, is solved by using the column generation approach~\cite{gg-61}.

\subsection{Formulation and notation}
\label{sec:formulation}

An instance of the UKP is a pair of a capacity~\(c\) and a list of~\(n\) items.
We Each item can be referenced by its index in the item list~\(i \in \{1,~\dots,~n\}\).
Each item~\(i\) has a weight value~\(w_i\), and a profit value~\(p_i\).
A solution is an item multiset (i.e., a set that allows multiple copies of the same element).
The sum of the items weight, or profit, of a solution~\(s\) is denoted by~\(w_s\), or~\(p_s\), and is referred to as the weight, or profit, of the solution.
A solution~\(s\) is valid iff~\(w_s \leq c\).
An optimal solution~\(s^*\) is a valid solution with the greatest profit value among all valid solutions.
To solve an instance of the UKP is to find an optimal solution for that instance.
%The profit value shared by all optimal solutions is denoted by \(p_{s^*}\).
%We refer to the profit value shared among all optimal solutions for a capacity~\(y\) as~\(opt(y)\), if we omit the capacity then~\(c\) is implied.

The mathematical formulation of UKP is:

\begin{align}
  \mbox{maximize} &\sum_{i=1}^n p_i x_i\label{eq:objfun}\\
\mbox{subject~to} &\sum_{i=1}^n w_i x_i \leq c\label{eq:capcons},\\
            &x_i \in \mathbb{N}_0.\label{eq:x_integer}
\end{align}

The quantities of each item~\(i\) in a solution are denoted by~\(x_i\), and are restricted to the non-negative integers, as~equation~\eqref{eq:x_integer} indicates. 
We assume that the capacity~\(c\), the quantity of items~\(n\) and the weights of the items~\(w_i\) are positive integers, while the profit values of the items~\(p_i\) are positive real numbers.

The efficiency of an item~\(i\) is its profit-to-weight ratio (\(\frac{p_i}{w_i}\)), and is denoted by~\(e_i\). 
We use~\(w_{min}\), or~\(w_{max}\), to denote the lowest weight among all items, or the highest weight among all items, within an instance of the UKP.
We refer to the item with the greatest efficiency among all items of a specific instance as the \emph{best item} (or~\(b\)). If more than one item shares the greatest efficiency, then the item with the lowest weight among them is considered the best item type; if more than an item has both previously stated characteristics, then the first item with both characteristics in the items list is the best item.

\subsection{Prior work}

To contextualize the reader, the authors present some selected papers related to the UKP and a summary of their relevance for the UKP.

\begin{table}[!htb]
\renewcommand{\arraystretch}{1.5}
\label{tab:prior_work}
%\begin{adjustbox}{max width=\textwidth, center}
\begin{tabu}{clp{10cm}}
Year & Ref. & Notes\\
\hline
1961 & \cite{gg-61} & The column generation approach for BPP and CSP continuous relaxation is proposed, the UKP is the pricing problem of such approach.\\
1966 & \cite{gg-66} & The ordered and the terminating step-off algorithms (dynamic programming algorithms to solve the UKP) are proposed. \\
1977 & \cite{mtu1} & The MTU1 (branch-and-bound algorithm) is proposed, and then compared with the previous algorithms over artificial instances up to a hundred items, obtaining marginally better results \\
1990 & \cite{mtu2} & Datasets of instances with up to 250,000 items (but rich in simple and multiple dominance) are proposed. MTU2 is proposed as an improvement of MTU1 for such dataset.\\
%1997 & \cite{zhu_dominated} & Uncorrelated datasets are shown to  \\
%1997 & \cite{babayev} & A new solving approach, more similar to dynamic programming than B\&B \\
1998 & \cite{ukp_new_results,eduk} & The EDUK (a dynamic programming algorithm) is proposed. Threshold dominance is proposed. EDUK is the first algorithm to exploit collective and threshold dominance. Old datasets receive some criticism for their high percentage of dominated items. New artificial datasets without the same flaws of the previous datasets are proposed. EDUK is compared to MTU2.\\
%2000 & \cite{eduk} & The new DP method only compares to B\&B and naive DP, the old non-naive DP algorithms were forgotten or excluded because of previous experiments. \\
2004 & \cite{book_ukp_2004} & A book on knapsack problems cite EDUK as state-of-the-art dynamic programming for the UKP. \\
2009 & \cite{pya} & EDUK2 is proposed. It consists in EDUK hybridized with B\&B. The datasets are updated to be `harder'. MTU2 is used in some comparisons, but not all because it has the risk of integer overflow. EDUK2 is compared to EDUK.\\ %Such datasets are hard for B\&B, and the hybrid method is only compared to B\&B. The hybrid method is the new state-of-the-art. \\
2016 & \cite{sea2016} & The terminating step-off is reinvented (with the name of UKP5) and outperforms the hybrid method in the updated datasets.\\
\end{tabu}
%\end{adjustbox}
\end{table}

\subsection{Properties of the UKP}
\label{sec:well_known_prop}

Algorithms that solve the UKP often exploit two properties to reduce the problem size: \emph{dominance} and \emph{periodicity}.
Dominance relations are exploited to reduce~\(n\), and periodicity is exploited to reduce~\(c\).

\subsubsection{Simple, multiple, collective and threshold dominance}

Any item~\(j\) that does not appear in all optimal solutions of an instance can be excluded without affecting our capability of solving such instance.
Given two items~\(i\) and~\(j\), if~\(w_i \leq w_j\) and~\(p_i \geq p_j\), then~\(j\) cannot be in all optimal solutions, since that for any optimal solution that contains~\(j\) there will exist another optimal solution with~\(i\) in the place of~\(j\).
Consequently, \(j\)~can be ignored when solving an instance that contains both~\(i\) and~\(j\).
Such relationship between~\(i\) and~\(j\) is called \emph{simple dominance}, more specifically we can say that~\(i\) simple dominate~\(j\) (or that~\(j\) is simple dominated by~\(i\)).

Given a positive integer~\(\alpha\), if~\(\alpha \times w_i \leq w_j\) and~\(\alpha \times p_i \geq p_j\), then~\(\alpha\) copies of~\(i\) can replace one of~\(j\),  and~\(j\) can be safely ignored.
Such relationship is called \emph{multiple dominance}, and it generalizes simple dominance in which \(\alpha = 1\).

Given a valid solution~\(s\), if~\(w_s \leq w_j\) and~\(p_s \geq p_j\), then the items that compose~\(s\) can replace~\(j\), and~\(j\) can be safely ignored.
Such relationship is called \emph{collective dominance} \cite{ukp_new_results}, and it generalizes multiple dominance in which~\(s\) consists of~\(\alpha\) copies of~\(i\).

If~\(w_s \leq \alpha \times w_j\) and~\(p_s \geq \alpha \times p_j\), then the items that compose~\(s\) can replace~\(\alpha\) copies of~\(j\), and solutions including~\(\alpha\) or more copies of~\(j\) can be safely ignored.
Such relationship is called \emph{threshold dominance}, and it generalizes collective dominance in which \(\alpha = 1\).
Threshold dominance with~\(\alpha > 1\) does not allow to exclude an item~\(j\) as a preprocessing phase, but it reduces the search space by allowing the algorithm to ignore all solutions in which~\(x_j \geq \alpha\).

%\begin{figure}
%  \centering
%  \includegraphics[width=1\textwidth]{smc_dominance}
%  \caption{Classical graphic representation of the simple, multiple and threshold dominances. Source: \cite{eduk}. All points in the shaded area created by an item or solution triangle are dominated.}
%\end{figure}

% TODO: maybe create and add image
%\begin{figure}
%  \centering
%  \includegraphics[width=1\textwidth]{threshold_dominance}
%  \caption{Classical graphic representation of the threshold dominance. Source: \cite{eduk}. The \(t_i\) is the \emph{t}hreshold of item \(i\), i.e. the weight of the smallest solution composed only of copies of \(i\) that is dominated by another item/solution.}
%\end{figure}

\subsubsection{Periodicity}

The \emph{periodicity} property shows the existence of a capacity \(y^+\).
After such capacity, all items but the best one are dominated.
For every capacity~\(y'\) (\(y' > y^+\)) there exists an optimal solution that is an optimal solution for capacity~\(y' - w_b\) with one more copy of the best item added.
In other words, for capacities greater than~\(y^+\), we can find an optimal solution by adding copies of the best item to an optimal solution of capacity~\(y^+\) or lower.
If~\(y^+ < c\), then the UKP can be solved for the capacity~\(y^{*} = c - \ceil{\frac{c - y^+}{w_b}}w_b\), and the gap between~\(y^{*}\) and~\(c\) filled with exactly~\(\frac{c - y^{*}}{w_b}\) copies of the best item \(b\), effectively reducing the knapsack size of the instance from~\(c\) to~\(y^*\).

The periodicity property is a direct consequence of the threshold dominance.
Except by the best item~\(b\), every item~\(j\) (\(j \neq b\)) is threshold dominated for some~\(\alpha_j\).
For example, given that~\(y\) is the lowest common multiple of~\(w_b\) and~\(w_j\),~\(\beta_j = \frac{y}{w_b}\) and~\(\alpha_j = \frac{y}{w_j}\), then~\(\beta_j \times w_b \leq \alpha_j \times w_j\) and~\(\beta_j \times p_b \geq \alpha_j \times p_j\). %, since \(e_b \geq e_j\) (from the definition of the best item).
Consequently, the threshold dominance defines a constraint~\(x_j < \alpha_j\) on every item~\(j\), and solutions that break such constraints can be safely ignored.
All solutions that do not break such constraints and do not make use of the best item weight less than~\(y'' = \sum \alpha_j \times w_j\).
Consequently, an optimal solution for any capacity greater than \(y''\) can be obtained by the procedure described in the last paragraph.
The capacity~\(y''\) is a upper bound on~\(y^+\)~\cite[p.~215]{book_ukp_2004}. %The computation of the exact value of~\(y^+\) is very expensive.
Computing~\(y^+\) would equal to solving the UKP for capacities~\(y^+\) and lower while checking for threshold dominance.
An upper bound on~\(y^+\) is less valuable than~\(y^+\) itself, but it can be computed in polynomial time, as a preprocessing phase.

\section{The ordered step-off and (weak) solution dominance}

The ordered step-off, a simple dynamic programming algorithm for the UKP from \cite{gg-66}, is described in Algorithm 1.%\autoref{alg:oso}. % ref not working with algorithm

\begin{algorithm}[!htb]
\caption{The ordered step-off (revisited)}
\begin{algorithmic}[1]
\Procedure{oso}{$n, c, w, p$}
  \State~Sort \(w\) and \(p\) by increasing item efficiency and find $w_{min}, w_{max}$ 
  \State~\(g \gets\) array of~\(c\) positions, initialized with~\(0\)\label{create_g}
  \State~\(d \gets\) array of~\(c\) positions, uninitialized\label{create_d}
  
  \For{\(i \gets 1, n\)}\label{begin_trivial_bounds}\Comment{Stores one-item solutions}
    \If{\(g[w_i] < p_i\)}
      \State~\(g[w_i] \gets p_i\)
      \State~\(d[w_i] \gets i\)
    \EndIf
  \EndFor\label{end_trivial_bounds}

  \State~\(opt \gets 0\)\label{init_opt}

  \For{\(y \gets w_{min}, c - w_{min}\)}\label{main_ext_loop_begin}%\Comment{Can end earlier because of periodicity check}
    \If{\(g[y] \leq opt\)}\label{if_less_than_opt_begin}\Comment{Prunes dominated solutions}
        \State \textbf{continue}\label{alg:continue}\Comment{Ends current iteration and begins the next}
    \EndIf\label{if_less_than_opt_end}
    
    \State~\(opt \gets g[y]\)\label{update_opt}
    
    \For{\(i=1,d[y]\)}\label{main_inner_loop_begin}\Comment{Creates new solutions (never symmetric)}
      \If{\(g[y + w_i] < g[y] + p_i\)}\label{if_new_lower_bound_begin}
        \State~\(g[y + w_i] \gets g[y] + p_i\)
        \State~\(d[y + w_i] \gets i\)
%      \ElsIf{\(g[y + w_i] = g[y] + p_i \land i < d[y + w_i]\)}
%        \State~\(d[y + w_i] \gets i\)
      \EndIf\label{if_new_lower_bound_end}
    \EndFor\label{main_inner_loop_end}
  \EndFor\label{main_ext_loop_end}

  \For{\(y \gets c - w_{min} + 1, c\)}
    \If{\(g[y] > opt\)}
      \State~\(opt \gets g[y]\)
    \EndIf
  \EndFor
  \State \textbf{return}~\(opt\)

%  \For{\(y \gets c-w_{min}+1, c\)}\label{get_y_opt_loop_begin}\Comment{Removal of dominated solutions}
%    \If{\(g[y] > opt\)}\label{last_loop_inner_if}
%      \State~\(opt \gets g[y]\)
%      \State~\(y_{opt} \gets y\)
%    \EndIf
%  \EndFor\label{get_y_opt_loop_end}
\EndProcedure
\end{algorithmic}
\end{algorithm}

Solution dominance is a dominance relation proposed by the authors.
Solution dominance generalizes simple, multiple, collective and threshold dominance.
A solution \(t\) is solution dominated by a different solution \(s\) iff \(w_s \leq w_t\) and \(p_s \geq p_t\).
If a solution \(q\) is solution dominated, then any solution that is a superset of \(q\) could be discarded (or not generated) without risk of discarding all optimal solutions.
The concept of solution dominance alone is of little use if there is not a way to design an algorithm that makes use of it without excessive overhead.
The ordered step-off applies a weaker version of the concept of solution dominance.

The authors use the notation~\(min_{ix}(s)\) to refer to the lowest index among the items that compose the solution~\(s\).
The notation~\(max_{ix}(s)\) has analogue meaning.

When a solution~\(t\) is pruned because~\(s\) dominates~\(t\) (lines~\ref{if_less_than_opt_begin} to~\ref{if_less_than_opt_end}), some solutions~\(u\), where~\(t \subset u\), are not generated. 
If~\(s\) dominates~\(t\), and~\(t \subset u\), and~\(max_{ix}(u - t) \leq min_{ix}(t)\), then~\(u\) is not generated by the ordered step-off algorithm. 
For example, if~\(\{3, 2\}\) is dominated, then~\(\{3, 2, 2\}\) and~\(\{3, 2, 1\}\) will never be generated by ordered step-off, but~\(\{3,2,3\}\) or~\(\{3,2,5\}\) could yet be generated (note that, in reality, it is the ordered equivalent~\([3,3,2]\) and~\([5,3,2]\) that could yet be generated).
Ideally, any~\(u\) where~\(t \subset u\) should not be generated as it would be dominated by a solution~\(u'\) where~\(s \subset u'\). 
It is interesting to note that this happens eventually, as any~\(t \cap \{i\}\) where~\(i > min_{ix}(t)\) will be dominated by~\(s \cap \{i\}\) (or by a solution that dominates~\(s \cap \{i\}\)), and at some point no solution that is a superset of~\(t\) will be generated anymore.

EDUK2, which was considered the state-of-the-art algorithm for the UKP by \cite{book_ukp_2004}, exploits the simple, multiple, collective and threshold dominance.
EDUK2 keeps a global item list, if an item is found to be dominated, it is removed from the list.
If the global item list is reduced to a single item (the best item), the algorithm stops. 
The ordered step-off keeps an index in each solution to mark which items can still be added to that solution.
The terminating step-off is a variant of the ordered step-off which detects if the only item that can be yet used is the best item, and stops the algorithm if this is the case.

If these periodicity checks stop their respective algorithm at capacity \(y\), they save the effort of iterating the last \(c - y\) positions.
However, in the positions \([y,c]\) the algorithm would not execute \(O(n)\) steps anymore, but only \(O(1)\) steps, as only the best item is yet relevant.
These periodicity checks are a small optimization in comparison to the application of dominance checks that make them possible.
An overlooked consequence of dominance is that it greatly reduces the usefulness of computing upper bounds on \(y^+\).
When EDUK2 global item list is reduced to the best item, the exact value of \(y^+\) is found.
In an algorithm with periodicity checking, the utility of upper bounds on~\(y^+\) is restricted to saving memory and saving the time spent initializing it.
%If an upper bound on \(y^+\) can be computed, item dominance and the periodicity checks stops the algorithm before the capacity predicted by the upper bound.

