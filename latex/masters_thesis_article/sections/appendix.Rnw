\section{Supplementary Materials}

\subsection{Summary Tables}

<<pya_tables_shared,echo=F>>=
get_dist <- function(fname) {
  gsub("([^_]+).*", "\\1", fname)
}

get_alpha <- function(fname) {
  as.numeric(gsub(".*a([5-][5]?).*", "\\1", fname))
}

get_n <- function(fname) {
  as.numeric(gsub(".*[^i]n([1-9][0-9]+).*", "\\1", fname))
}

get_wmin <- function(row) {
  if (row['dist'] == 'hi') {
    as.numeric(row['n'])
  } else {
    as.numeric(gsub(".*wmin([1-9][0-9]+).*", "\\1", row['filename']))
  }
}
@

<<pya_fast_table,echo=F>>=
ft <- read.csv("../data/pya_ukp5.csv", sep = ";")
ft$X <- NULL

# we only show the results for the terminating_step_off
ft <- filter(ft, algorithm != 'ordered_step_off')
# adding extra columns parsed from filename
ft <- ft %>%
  mutate(dist = get_dist(filename)) %>%
  mutate(a = get_alpha(filename)) %>%
  mutate(n = get_n(filename))
ft$wmin <- apply(ft, 1, get_wmin)

# this ordering is necessary to make_pya_row put the columns in the right places
ft$algorithm <- factor(ft$algorithm, levels = c('terminating_step_off', 'mgreendp', 'pyasukp'))
ft <- arrange(ft, algorithm)

# subset-sum results are not discriminated by parameter combination
ss2 <- ft %>%
  filter(dist == "ss2") %>%
  select(algorithm, internal_time) %>%
  group_by(algorithm) %>%
  summarise(
    avg = mean(internal_time),
    sd  =   sd(internal_time),
    max =  max(internal_time))

ft <- ft %>%
  select(algorithm, dist, a, n, wmin, internal_time) %>%
  group_by(algorithm, dist, a, n, wmin) %>%
  summarise(
    avg = mean(internal_time),
    sd  =   sd(internal_time),
    max =  max(internal_time))

nsds2 <- filter(ft, dist == 'nsds2')
hi <- filter(ft, dist == 'hi')
saw <- filter(ft, dist == 'saw')
sc <- filter(ft, dist == 'sc')

make_pya_row <- function(t, ...) {
  tt <- ungroup(t)
  tt <- filter(tt, ...)
  tt <- select(tt, avg, sd, max)
  min_avg <- min(tt$avg, na.rm = T)
  tt$avg <- sapply(tt$avg, function(x) {
    if (is.na(x)) {
      "--"
    } else if(x == min_avg) {
      paste0("\\textbf{", sprintf("%.2f", x), "}")
    } else {
      sprintf("%.2f", x)
    }
  })
  f <- function (x) {
    if (is.na(x)) {
      "--"
    } else {
      sprintf("%.2f", x)
    }
  }
  tt$sd <- sapply(tt$sd, f)
  tt$max <- sapply(tt$max, f)
  paste(apply(tt, 1, paste, collapse=" & "), collapse = " & ")
}
@

\begin{table}[H]
\caption{Results for the PYAsUKP 4540 Instances (see Section \ref{sec:pya_exp}). Columns \textbf{n} and \(w_{min}\) values must be multiplied by \(10^3\) to obtain their true value. Let \(T\) be the set of run times reported by the Terminating Step-Off, GREENDP or EDUK2 for the instance dataset described by a row. The meaning of the columns \textbf{avg}, \textbf{sd} and \textbf{max}, is, respectively, the arithmetic mean of \(T\), the standard deviation of \(T\), the maximum value of \(T\). The time unit of the table values is seconds.}
\vspace{1mm}
\label{tab:times_pya}
\def\arraystretch{1.1}
\setlength\tabcolsep{4px}

\begin{adjustbox}{max width=\textwidth, center}
\begin{tabular}{@{\extracolsep{4pt}}rrrrrrrrrrrr@{}}

\hline
\multicolumn{3}{l}{Instance desc.} & \multicolumn{3}{l}{TSO} & \multicolumn{3}{l}{GREENDP} & \multicolumn{3}{l}{PYAsUKP}\\
\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}

\multicolumn{3}{l}{400 inst. per line} & \multicolumn{9}{l}{Subset-sum. Random \emph{c} between \([5\times10^6; 10^7]\)}\\
\cline{1-3}\cline{4-12}

& \textbf{n} & \(w_{min}\)  & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max}\\
\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}

\multicolumn{3}{c}{For detail see~\cite{sea2016}} & \Sexpr{make_pya_row(ss2)}\\ % & 0.05 & 0.12 & 0.74 & -- & -- & -- & 2.52 & 21.75 & 302.51 \\
\hline

\multicolumn{3}{l}{20 inst. per line} & \multicolumn{9}{l}{Strong correlation. Random \emph{c} between \([20\overline{n}; 100\overline{n}]\)}\\
\cline{1-3}\cline{4-12}
\textbf{\(\alpha\)} & \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max}\\

\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}
 5 & 5  & 10 & \Sexpr{make_pya_row(sc, a == 5 & n == 5000 & wmin == 10000)}\\
   &    & 15 & \Sexpr{make_pya_row(sc, a == 5 & n == 5000 & wmin == 10000)}\\%0.04 & 0.00 & 0.05 &  0.43 & 0.06 &  0.53 & 3.85 & 1.53 & 5.13\\
   &    & 50 & \Sexpr{make_pya_row(sc, a == 5 & n == 5000 & wmin == 10000)}\\%0.13 & 0.00 & 0.16 &  1.01 & 0.52 &  1.70 & 12.12 & 8.17 & 28.84\\
 5 & 10 & 10 & \Sexpr{make_pya_row(sc, a == 5 & n == 5000 & wmin == 10000)}\\%0.06 & 0.00 & 0.06 &  0.50 & 0.04 &  0.54 & 0.00 & 0.00 & 0.01\\
   &    & 50 & \Sexpr{make_pya_row(sc, a == 5 & n == 5000 & wmin == 10000)}\\%0.29 & 0.00 & 0.30 &  5.93 & 0.82 &  6.79 & 22.43 & 17.85 & 45.19\\
   &    & 110& \Sexpr{make_pya_row(sc, a == 5 & n == 5000 & wmin == 10000)}\\%0.66 & 0.00 & 0.66 & 16.05 & 3.36 & 19.68 & 76.53 & 62.54 & 175.61\\
-5 & 5  & 10 & \Sexpr{make_pya_row(sc, a == -5 & n == 5000 & wmin == 10000)}\\%0.04 & 0.00 & 0.05 & 0.04 & 0.00 & 0.04 & 4.02 & 2.72 & 7.12\\
   &    & 15 & \Sexpr{make_pya_row(sc, a == -5 & n == 5000 & wmin == 10000)}\\%0.05 & 0.00 & 0.05 & 0.05 & 0.00 & 0.05 & 6.76 & 4.22 & 12.24\\
   &    & 50 & \Sexpr{make_pya_row(sc, a == -5 & n == 5000 & wmin == 10000)}\\%0.14 & 0.00 & 0.15 & 0.11 & 0.02 & 0.12 & 24.76 & 19.41 & 66.23\\
-5 & 10 & 10 & \Sexpr{make_pya_row(sc, a == -5 & n == 10000 & wmin == 10000)}\\%0.10 & 0.00 & 0.10 & 0.11 & 0.01 & 0.13 & 6.74 & 6.28 & 15.38\\
   &    & 50 & \Sexpr{make_pya_row(sc, a == -5 & n == 10000 & wmin == 10000)}\\%0.32 & 0.00 & 0.32 & 0.28 & 0.01 & 0.29 & 48.70 & 42.53 & 111.61\\
   &    & 110& \Sexpr{make_pya_row(sc, a == -5 & n == 10000 & wmin == 10000)}\\%0.65 & 0.00 & 0.66 & 0.52 & 0.01 & 0.53 & 144.87 & 143.53 & 416.41\\
\hline

\multicolumn{3}{l}{200 inst. per line} & \multicolumn{9}{l}{Postponed periodicity. Random \emph{c} between \([w_{max}; 2\times10^6]\)}\\
\cline{1-3}\cline{4-12}
& \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max}\\
\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}
& 20 & 20 & \Sexpr{make_pya_row(nsds2, n == 20000 & wmin == 20000)}\\%0.79 & 0.10 & 0.97 & 0.74 & 0.11 & 0.96 & 8.65 & 7.74 & 28.63\\
& 50 & 20 & \Sexpr{make_pya_row(nsds2, n == 50000 & wmin == 20000)}\\%5.70 & 0.37 & 6.54 & 5.12 & 0.65 & 6.13 & 78.34 & 82.46 & 356.67\\
& 20 & 50 & \Sexpr{make_pya_row(nsds2, n == 20000 & wmin == 50000)}\\%0.89 & 0.12 & 1.19 & 0.75 & 0.14 & 1.09 & 11.57 & 8.20 & 39.20\\
& 50 & 50 & \Sexpr{make_pya_row(nsds2, n == 50000 & wmin == 50000)}\\%4.72 & 0.69 & 6.27 & 3.97 & 0.75 & 5.30 & 113.21 & 87.16 & 267.10\\
\hline

\multicolumn{3}{l}{500 inst. per line} & \multicolumn{9}{l}{No collective dominance. Random \emph{c} between \([w_{max}; 1000\overline{n}]\)}\\
\cline{1-3}\cline{4-12}
& \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max}\\
\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}
&  5 & n & \Sexpr{make_pya_row(hi, n == 5000 & wmin == 5000)}\\% 0.07 & 0.03 & 0.14 & 0.04 & 0.01 & 0.07 & 0.59 & 0.44 & 2.03\\
& 10 & n & \Sexpr{make_pya_row(hi, n == 10000 & wmin == 10000)}\\% 0.65 & 0.31 & 1.30 & 0.33 & 0.10 & 0.60 & 2.34 & 1.86 & 8.44\\
& 20 & n & \Sexpr{make_pya_row(hi, n == 20000 & wmin == 20000)}\\% 1.04 & 0.32 & 1.91 & 0.72 & 0.12 & 1.31 & 8.62 & 7.64 & 31.22\\
& 50 & n & \Sexpr{make_pya_row(hi, n == 50000 & wmin == 50000)}\\% 3.64 & 0.36 & 4.74 & 3.56 & 0.20 & 4.46 & 73.49 & 72.26 & 279.01\\
\hline

\multicolumn{3}{l}{\emph{qtd} inst. per line} & \multicolumn{9}{l}{SAW. Random \emph{c} between \([w_{max}; 10\overline{n}]\)}\\
\cline{1-3}\cline{4-12}
\textbf{qtd} & \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max} & \textbf{avg} & \textbf{sd} & \textbf{max}\\
\cline{1-3}\cline{4-6}\cline{7-9}\cline{10-12}
~200 &  10 & 10 & \Sexpr{make_pya_row(saw, n == 10000 & wmin == 10000)} \\%0.08 & 0.00 & 0.09 & 0.14 & 0.02 & 0.21 & 1.32 & 0.85 & 3.01\\
~500 &  50 &  5 & \Sexpr{make_pya_row(saw, n == 50000 & wmin == 5000)}  \\%0.50 & 0.01 & 0.53 & 2.09 & 1.00 & 3.75 & 3.36 & 2.86 & 11.16\\
~200 &  50 & 10 & \Sexpr{make_pya_row(saw, n == 50000 & wmin == 10000)} \\%0.72 & 0.01 & 0.74 & 2.15 & 0.85 & 3.65 & 6.99 & 5.81 & 23.04\\
~200 & 100 & 10 & \Sexpr{make_pya_row(saw, n == 100000 & wmin == 10000)}\\%7.34 & 0.32 & 8.09 & 33.93 & 6.94 & 43.40 & 40.43 & 35.13 & 118.28\\
\hline

\end{tabular}
\end{adjustbox}
\end{table}

\clearpage

<<pya_mtu_table,echo=FALSE>>=
st<- read.csv("../data/mtus_pya.csv", sep = ";")
st$X <- NULL

# adding extra columns parsed from filename
st <- st %>%
  mutate(dist = get_dist(filename)) %>%
  mutate(a = get_alpha(filename)) %>%
  mutate(n = get_n(filename))
st$wmin <- apply(st, 1, get_wmin)

# this ordering is necessary to make_pya_row put the columns in the right places
st$algorithm <- factor(st$algorithm, levels = c('fmtu1', 'cpp-mtu1', 'fmtu2', 'cpp-mtu2'))
st <- arrange(st, algorithm)

# subset-sum results are not discriminated by parameter combination
mt_ss2 <- st %>%
  filter(dist == "ss2") %>%
  select(algorithm, internal_time) %>%
  group_by(algorithm) %>%
  summarise(
    avg = sprintf("%.2f", mean(internal_time, na.rm = T)),
    fin = sum(!is.na(internal_time)))
mt_ss2[] <- lapply(mt_ss2, function(x) { gsub('NaN', '--', x) })

st <- st %>%
  select(algorithm, dist, a, n, wmin, internal_time) %>%
  group_by(algorithm, dist, a, n, wmin) %>%
  summarise(
    avg = sprintf("%.2f", mean(internal_time, na.rm = T)),
    fin = sum(!is.na(internal_time)))
st[] <- lapply(st, function(x) { gsub('NaN', '--', x) })

mt_nsds2 <- filter(st, dist == 'nsds2')
mt_hi <- filter(st, dist == 'hi')
mt_saw <- filter(st, dist == 'saw')
mt_sc <- filter(st, dist == 'sc')

make_mtu_row <- function(t, ...) {
  tt <- ungroup(t)
  tt <- filter(tt, ...)
  tt <- select(tt, avg, fin)
  paste(apply(tt, 1, paste, collapse=" & "), collapse = " & ")
}
@

% TODO: put explanation of the overline in the caption, because it's used
% in the explanation of capacities, do this for both pya tables
%"TODO: decide what to put in the section reference of subset-sum instances
\begin{table}[H]
\caption{Results for the MTU implementatios over the reduced PYAsUKP's dataset (see Section \ref{sec:mtu_exp}). Columns \textbf{n} and \(w_{min}\) values must be multiplied by \(10^3\) to obtain their true value. Let \(T\) be the set of run times reported by CPP-MTU1, CPP-MTU2, F77-MTU1 and F77-MTU2, for the instance dataset described by a row (in this case, we don't count runs that ended in timeout). The meaning of the columns \textbf{avg} and \textbf{fin}ished, is, respectively, the arithmetic mean of \(T\) and the cardinality of \(T\) (i.e. the number of runs that didn't end in timeout). The time unit of the table values is seconds.}
\label{tab:times_mtu}
\vspace{1mm}
\def\arraystretch{1.1}
\setlength\tabcolsep{6px}

\begin{adjustbox}{max width=\textwidth, center}
\begin{tabular}{@{\extracolsep{4pt}}rrrrrrrrrrr@{}}

\hline
\multicolumn{3}{l}{Instance desc.} & \multicolumn{2}{c}{F77-MTU1} & \multicolumn{2}{c}{CPP-MTU1} & \multicolumn{2}{c}{F77-MTU2} & \multicolumn{2}{c}{CPP-MTU2}\\
\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}

\multicolumn{3}{l}{40 inst. per line} & \multicolumn{8}{l}{Subset-sum. Random \emph{c} between \([5\times10^6; 10^7]\)}\\
\cline{1-3}\cline{4-11}

& \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{fin}  & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin}\\
\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}

\multicolumn{3}{c}{For detail see~\cite{sea2016}} & \Sexpr{make_mtu_row(mt_ss2)}\\ %0.04 & 40 & 0.04 & 40 & 0.00 & 40 & 154.97 & 8\\
\hline

\multicolumn{3}{l}{20 inst. per line} & \multicolumn{8}{l}{Strong correlation. Random \emph{c} between \([20\overline{n}; 100\overline{n}]\)}\\
\cline{1-3}\cline{4-11}
\textbf{\(\alpha\)} & \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{fin}  & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin}\\

\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}
 5 & 5  & 10 & \Sexpr{make_mtu_row(mt_sc, a == 5 & n == 5000 & wmin == 10000)}\\%0.00 & 1 &   -- & 0 & 0.00 & 1 &   -- & 0\\
   &    & 15 & \Sexpr{make_mtu_row(mt_sc, a == 5 & n == 5000 & wmin == 15000)}\\%  -- & 0 &   -- & 0 &   -- & 0 &   -- & 0\\
   &    & 50 & \Sexpr{make_mtu_row(mt_sc, a == 5 & n == 5000 & wmin == 50000)}\\%  -- & 0 &   -- & 0 &   -- & 0 &   -- & 0\\
 5 & 10 & 10 & \Sexpr{make_mtu_row(mt_sc, a == 5 & n == 10000 & wmin == 10000)}\\%0.00 & 1 &   -- & 0 & 0.00 & 1 &   -- & 0\\
   &    & 50 & \Sexpr{make_mtu_row(mt_sc, a == 5 & n == 10000 & wmin == 50000)}\\%0.04 & 1 &   -- & 0 & 0.03 & 1 &   -- & 0\\
   &    & 110& \Sexpr{make_mtu_row(mt_sc, a == 5 & n == 10000 & wmin == 110000)}\\%0.01 & 1 &   -- & 0 & 0.00 & 1 &   -- & 0\\
-5 & 5  & 10 & \Sexpr{make_mtu_row(mt_sc, a == -5 & n == 5000 & wmin == 10000)}\\%  -- & 0 &   -- & 0 &   -- & 0 &   -- & 0\\
   &    & 15 & \Sexpr{make_mtu_row(mt_sc, a == -5 & n == 5000 & wmin == 15000)}\\%  -- & 0 &   -- & 0 &   -- & 0 &   -- & 0\\
   &    & 50 & \Sexpr{make_mtu_row(mt_sc, a == -5 & n == 5000 & wmin == 50000)}\\%  -- & 0 &   -- & 0 &   -- & 0 &   -- & 0\\
-5 & 10 & 10 & \Sexpr{make_mtu_row(mt_sc, a == -5 & n == 10000 & wmin == 10000)}\\%0.00 & 1 &   -- & 0 & 0.00 & 1 &   -- & 0\\
   &    & 50 & \Sexpr{make_mtu_row(mt_sc, a == -5 & n == 10000 & wmin == 50000)}\\%0.00 & 1 & 0.79 & 1 & 0.00 & 1 & 0.83 & 1\\
   &    & 110& \Sexpr{make_mtu_row(mt_sc, a == -5 & n == 10000 & wmin == 110000)}\\%0.00 & 1 &   -- & 0 & 0.00 & 1 &   -- & 0\\
\hline

\multicolumn{3}{l}{20 inst. per line} & \multicolumn{8}{l}{Postponed periodicity. Random \emph{c} between \([w_{max}; 2\times10^6]\)}\\
\cline{1-3}\cline{4-11}
& \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{fin}  & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin}\\
\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}
& 20 & 20 & \Sexpr{make_mtu_row(mt_nsds2, n == 20000 & wmin == 20000)}\\%67.17 & 19 & 67.17 & 19 &  18.05 & 17 &  15.12 & 17\\
& 50 & 20 & \Sexpr{make_mtu_row(mt_nsds2, n == 50000 & wmin == 20000)}\\% 1.93 & 18 &  2.15 & 20 & 134.09 & 17 & 143.47 & 17\\
& 20 & 50 & \Sexpr{make_mtu_row(mt_nsds2, n == 20000 & wmin == 50000)}\\% 3.15 & 20 &  1.74 & 20 &   6.33 & 20 &   7.83 & 20\\
& 50 & 50 & \Sexpr{make_mtu_row(mt_nsds2, n == 50000 & wmin == 50000)}\\% 2.22 & 20 & 21.13 & 20 &   4.45 & 20 &  13.81 & 20\\
\hline

\multicolumn{3}{l}{50 inst. per line} & \multicolumn{8}{l}{No collective dominance. Random \emph{c} between \([w_{max}; 1000\overline{n}]\)}\\
\cline{1-3}\cline{4-11}
& \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin}\\
\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}
&  5 & n & \Sexpr{make_mtu_row(mt_hi, n == 5000 & wmin == 5000)}  \\% 16.54 & 9 & 37.01 & 9 & 19.85 & 9 & 37.29 & 9\\
& 10 & n & \Sexpr{make_mtu_row(mt_hi, n == 10000 & wmin == 10000)}\\%147.08 & 6 &  5.84 & 5 & 34.41 & 5 & 10.09 & 5\\
& 20 & n & \Sexpr{make_mtu_row(mt_hi, n == 20000 & wmin == 20000)}\\% 17.95 & 3 & 19.23 & 3 & 27.45 & 3 & 27.78 & 3\\
& 50 & n & \Sexpr{make_mtu_row(mt_hi, n == 50000 & wmin == 50000)}\\% 13.36 & 2 &  1.40 & 2 & 26.73 & 2 &  2.64 & 2\\
\hline

\multicolumn{3}{l}{\emph{qtd} inst. per line} & \multicolumn{8}{l}{SAW. Random \emph{c} between \([w_{max}; 10\overline{n}]\)}\\
\cline{1-3}\cline{4-11}
\textbf{qtd} & \textbf{n} & \(w_{min}\) & \textbf{avg} & \textbf{fin}  & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin} & \textbf{avg} & \textbf{fin}\\
\cline{1-3}\cline{4-5}\cline{6-7}\cline{8-9}\cline{10-11}
~20 &  10 & 10 & \Sexpr{make_mtu_row(mt_saw, n ==  10000 & wmin == 10000)}\\% 1.33 & 20 & 12.92 & 20 &  2.54 & 20 &  2.87 & 20\\
~50 &  50 &  5 & \Sexpr{make_mtu_row(mt_saw, n ==  50000 & wmin == 5000)} \\%43.08 & 46 & 43.97 & 19 & 59.14 & 38 & 38.63 & 16\\
~20 &  50 & 10 & \Sexpr{make_mtu_row(mt_saw, n ==  50000 & wmin == 10000)}\\%55.14 & 45 & 87.68 & 19 & 47.05 & 41 & 85.97 & 19\\
~20 & 100 & 10 & \Sexpr{make_mtu_row(mt_saw, n == 100000 & wmin == 10000)}\\%10.10 & 16 & 38.41 & 17 & 20.23 & 16 & 44.41 & 16\\
\hline
\end{tabular}
\end{adjustbox}
\end{table}

\clearpage

<<rr_breq_shared_appendix>>=
get_n <- function(fname) {
  gsub(".*n([1-9][0-9]+).*", "\\1", fname)
}

format_n <- function(x) {
  str <- sprintf("%.2f", x)
  gsub("(NA|NaN)", "--", str)
}


pretiffy_alg_names <- function(names) {
  recode(names,
  'cpp-mtu1'             = 'MTU1 (C++)',
  'cpp-mtu2'             = 'MTU2 (C++)',
  'eduk'                 = 'EDUK',
  'eduk2'                = 'EDUK2',
  'ordered_step_off'     = 'Ord. Step-Off',
  'terminating_step_off' = 'Term. Step-Off',
  'mgreendp'             = 'GREENDP')
}
@

<<rr_table_appendix,results='asis'>>=
rr <- read.csv("../data/realistic_random.csv", sep = ";")
rr$X <- NULL

#rr <- filter(rr,
#  algorithm != 'terminating_step_off' &
#  algorithm != 'ordered_step_off')
rr$algorithm <- pretiffy_alg_names(rr$algorithm)
rt <- rr %>% mutate(n = as.integer(get_n(filename))) %>%
  select(algorithm, n, internal_time) %>% group_by(algorithm, n) %>%
  summarise(avg = format_n(mean(internal_time, na.rm = TRUE)),
            sd  = format_n(  sd(internal_time, na.rm = TRUE)),
            min = format_n( min(internal_time, na.rm = TRUE)),
            max = format_n( max(internal_time, na.rm = TRUE)),
            fin = sum(!is.na(internal_time))) #%>%
  #arrange(n, algorithm)

# "The results for the step-offs were ommited as they are very similar to the GREENDP results."
lrt <- xtable(rt, caption = "Results of the experiment with realistic random dataset (see \\autoref{sec:rr_exp}). For each row, there is a set \\(T\\) comprised by the run times that \\textbf{algorithm} spent solving instances of size \\textbf{n}. We do not count the run time of runs that ended in timeout. The meaning of the columns \\textbf{avg}, \\textbf{sd}, \\textbf{min}, \\textbf{max} and \\textbf{fin} are, respectively, the arithmetic mean of \\(T\\), the standard deviation of \\(T\\), the minimal value in \\(T\\), the maximal value in \\(T\\), and the cardinality of \\(T\\) (i.e. the number of runs that did not end in timeout). The time unit of the table values is seconds.", label = 'tab:rr')
align(lrt) <- c('r', 'c', rep('r', 5), 'c')
print(lrt, hline.after=c(-1, 0), tabular.environment = "longtable", floating=F, add.to.row = list(pos = list(0), command = "\\hline \\endhead ")) 
@

<<breq_table_appendix,echo=FALSE,results='asis'>>=
breq <- read.csv("../data/128_16_std_breqd.csv", sep = ";")
breq$X <- NULL

breq$algorithm <- pretiffy_alg_names(breq$algorithm)
bt <- breq %>% mutate(n = as.integer(get_n(filename))) %>%
  select(algorithm, n, internal_time) %>% group_by(algorithm, n) %>%
  summarise(avg = format_n(mean(internal_time, na.rm = TRUE)),
            sd  = format_n(  sd(internal_time, na.rm = TRUE)),
            min = format_n( min(internal_time, na.rm = TRUE)),
            max = format_n( max(internal_time, na.rm = TRUE)),
            fin = sum(!is.na(internal_time))) #%>%
  #arrange(n, algorithm)

lt <- xtable(bt, caption = "Results of the BREQ 128-16 Standard Benchmark (see Section \\ref{sec:breq_exp}). For each row, there is a set \\(T\\) comprised by the run times that \\textbf{algorithm} spent solving instances of size \\textbf{n}. We do not count the run time of runs that ended in timeout. The meaning of the columns \\textbf{avg}, \\textbf{sd}, \\textbf{min}, \\textbf{max} and \\textbf{fin} are, respectively, the arithmetic mean of \\(T\\), the standard deviation of \\(T\\), the minimal value in \\(T\\), the maximal value in \\(T\\), and the cardinality of \\(T\\) (i.e. the number of runs that did not end in timeout). The time unit of the table values is seconds.", label = 'tab:breq')
align(lt) <- c('r', 'c', rep('r', 5), 'c')
print(lt, hline.after=c(-1, 0), tabular.environment = "longtable", floating=F, add.to.row = list(pos = list(0), command = "\\hline \\endhead ")) 
@

\begin{table}
\label{tab:csp}
\caption{Results of the experiment focused in solving pricing subproblems of the BPP/CSP (see \autoref{sec:csp_experiments}). The results of solving the pricing problems with CPLEX are included here for completeness. The time limit was half an hour for the total run time (which includes reading input, the master time and the pricing time). The unit of all time columns is seconds. The meaning of each column is: N -- amount of instances in the respective dataset; N' -- amount of instances in which the solver coupled with the respective algorithm exceeded the time limit; Master time -- amount of time taken by CPLEX to solve the continuous relaxation (disregarding the solving of pricing problems); Pricing time -- mean time spent by the respective algorithm solving all pricing problems of a single instance of the respective dataset; \# of subproblems -- the mean amount of generated pricing problems in a single instance of the respective dataset (this amount is affected by the exact optimal solutions which were returned by the algorithm used to solve the pricing problems); Time per subproblem -- the result of the division of the two last columns. } 
\begin{adjustbox}{max width=\textwidth, center}
<<csp_table, results='asis'>>=
na_mean <- function(x) {
  base::mean(x, na.rm = T)
}

count_na <- function(x) {
  base::sum(is.na(x))
}

# Simple Format Float Significant Cases (and by simple I mean: without
# resorting to scientific notation)
sffsc <- function(digits, x, ...) {
  sprintf(paste0('%.', digits, 'f'), x, ...)
}

table_rows_csp <- function(t) {
  latex(
    tabular(
      dataset ~
	(n = 1) + count_na*total_iter +
        na_mean*#Justify('r')*
          (Format(sffsc(2))*hex_sum_master_prob_time + Format(sffsc(2))*pricing_total_time + total_iter + Format(sffsc(5))*(pricing_total_time/total_iter)),
      data = t
    ),
    mathmode = F,
    options = list(latexrightpad = F, latexleftpad = F, doBegin = F, doHeader = F, doFooter = F, doEnd = F)
  )
}

num_columns <- 7
#cat('\\begin{tabu} to \\linewidth { L{1} R{1} R{1} R{1} R{1} C{1} C{1} }\n')
cat('\\begin{tabu} to \\linewidth { lrrrrrr }\n')
cat('Dataset  & N & N\' & \\makecell{Master\\\\time} & \\makecell{Pricing\\\\time} & \\makecell{\\# of sub-\\\\problems} & \\makecell{Time per\\\\subproblem}\\\\\\\\')
#cat('\\hline\n')
cat("\\multicolumn{", num_columns, "}{c}{MTU1}\\\\\n", sep = '')
#cat('\\hline\n')
table_rows_csp(filter(csp_csv, algorithm == 'mtu1_cutstock'))
#cat('\\hline\n')
cat("\\multicolumn{", num_columns, "}{c}{CPLEX}\\\\\n", sep = '')
#cat('\\hline\n')
table_rows_csp(filter(csp_csv, algorithm == 'cplex_cutstock'))
#cat('\\hline\n')
cat("\\multicolumn{", num_columns, "}{c}{Ordered Step-off (integer, no sort)}\\\\\n", sep = '')
#cat('\\hline\n')
table_rows_csp(filter(csp_csv, algorithm == 'ordso_int_ns'))
cat('\\end{tabu}\n')
@
\end{adjustbox}
\end{table}

